{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import time\n",
    "\n",
    "import PIL\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import argparse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, data_frame: pd.DataFrame, root_dir: str, transform=None):\n",
    "        self.data_frame = data_frame\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = dict()\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_name = str(self.data_frame.iloc[idx]['id'])\n",
    "        img_path = os.path.join(self.root_dir, img_name+'.jpg')\n",
    "        image = PIL.Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        tag_name = self.data_frame.iloc[idx]['class']\n",
    "        \n",
    "        sample['image'] = image\n",
    "        sample['class'] = tag_name\n",
    "        \n",
    "        return sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "                [0.485, 0.456, 0.406], \n",
    "                [0.229, 0.224, 0.225])\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, criterion, epoch ):\n",
    "    \n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    for i, data in enumerate(train_loader):\n",
    "        x = data['image']\n",
    "        emotion = data['class']\n",
    "        x = x.to(device)\n",
    "        emotion = emotion.to(device)\n",
    "\n",
    "        optimizer.zero_grad() \n",
    "\n",
    "        out = model(x)\n",
    "\n",
    "        \n",
    "        loss = criterion(out, emotion)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item() / len(train_loader)\n",
    "        #print(f'epoch is {epoch} | train_loss is {train_loss}')\n",
    "    del x, emotion\n",
    "    torch.cuda.empty_cache()\n",
    "    return train_loss\n",
    "\n",
    "def validation(model, criterion, valid_loader):\n",
    "    \n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    label = []\n",
    "    prediction = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(valid_loader):\n",
    "            x = data['image']\n",
    "            emotion = data['class']\n",
    "            x = x.to(device)\n",
    "            emotion = emotion.to(device)\n",
    "            out = model(x)\n",
    "\n",
    "            \n",
    "            loss = criterion(out, emotion)\n",
    "            \n",
    "            pred = torch.argmax(out,dim=-1)\n",
    "            \n",
    "            val_loss += loss.item() / len(valid_loader)\n",
    "            \n",
    "            label = label + emotion.tolist()\n",
    "            prediction = prediction + pred.detach().cpu().tolist()\n",
    "        del x, emotion\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    val_score = f1_score(label, prediction, average='micro') \n",
    "    \n",
    "    return val_loss, val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(args,num_epochs=60, cv_checkpoint=True, fine_tune=False,\n",
    "                weight_file_name='weight_best.pt', **train_kwargs):\n",
    "    # choose scheduler\n",
    "    lr = args.learning_rate\n",
    "    optimizer = optim.AdamW(model.parameters(),lr = lr,weight_decay = 1e-5)   \n",
    "    scheduler = ReduceLROnPlateau(optimizer, 'min', patience=10, factor=0.9)\n",
    "    \n",
    "    train_result = {}\n",
    "    train_result['weight_file_name'] = weight_file_name\n",
    "    best_epoch = -1\n",
    "    best_score = 0.\n",
    "    lrs = []\n",
    "    score = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        start_time = time.time()\n",
    "\n",
    "        train_loss = train(model, train_loader, optimizer,criterion,epoch)\n",
    "        val_loss, val_score = validation(model, criterion, valid_loader)\n",
    "        score.append(val_score)\n",
    "\n",
    "        if cv_checkpoint:\n",
    "            if val_score > best_score:\n",
    "                best_score = val_score\n",
    "                train_result['best_epoch'] = epoch + 1\n",
    "                train_result['best_score'] = round(best_score, 5)\n",
    "                \n",
    "                torch.save(model.state_dict(), weight_file_name)\n",
    "                print(\"Score is higher than last model .....Saving Model.....\")\n",
    "        else:\n",
    "            if val_loss < best_loss:\n",
    "                best_loss = val_loss\n",
    "                train_result['best_epoch'] = epoch + 1\n",
    "                train_result['best_loss'] = round(best_loss, 5)\n",
    "                \n",
    "                torch.save(model.state_dict(), weight_file_name)\n",
    "        \n",
    "        elapsed = time.time() - start_time\n",
    "        now = time.localtime()\n",
    "        lr = [_['lr'] for _ in optimizer.param_groups]\n",
    "        print(\"Epoch {} - train_loss: {:.4f}  val_loss: {:.4f}  cv_score: {:.4f}  lr: {:.6f}  time: {:.0f}s nowtime: {},{}:{}.{}\".format(\n",
    "                epoch+1, train_loss, val_loss, val_score, lr[0], elapsed,now.tm_mday,now.tm_hour,now.tm_min,now.tm_sec))\n",
    "      \n",
    "        for param_group in optimizer.param_groups:\n",
    "            lrs.append(param_group['lr'])\n",
    "        \n",
    "        # scheduler update\n",
    "        if cv_checkpoint:\n",
    "            scheduler.step(val_score)\n",
    "        else:\n",
    "            scheduler.step(val_loss)\n",
    "       \n",
    "     \n",
    "    return train_result, lrs, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "args = parser.parse_args(\"\")\n",
    "\n",
    "df = pd.read_csv(f'../data/assignment/write.csv')\n",
    "data_dir = '../data/assignment/preprocessed_train/'\n",
    "\n",
    "SEED = 42\n",
    "seed_everything(SEED)\n",
    "args.batch_size = 128\n",
    "args.learning_rate = 0.001\n",
    "args.multi_parallel = True\n",
    "args.num_epochs = 2000\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "result_arr = []\n",
    "\n",
    "batch_size = args.batch_size\n",
    "#batch_size = 128*2\n",
    "traindataset = TrainDataset(df,root_dir = data_dir,transform = train_transform)\n",
    "train_set, val_set = torch.utils.data.random_split(traindataset, [int(len(traindataset)*0.8), len(traindataset)-int(len(traindataset)*0.8)])\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "model = EfficientNet.from_pretrained('efficientnet-b3', num_classes=5)\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(reduction='mean')\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "train_kwargs = dict(\n",
    "    train_loader=train_loader,\n",
    "    valid_loader=valid_loader,\n",
    "    model=model,\n",
    "    criterion=criterion,\n",
    ")\n",
    "\n",
    "num_epochs = args.num_epochs\n",
    "result, lrs, score = train_model(args,num_epochs=num_epochs, cv_checkpoint=True, fine_tune=False, **train_kwargs)\n",
    "result_arr.append(result)\n",
    "print(result)\n",
    "\n",
    "# learning rate plot\n",
    "plt.figure(figsize=(18,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(lrs, 'b')\n",
    "plt.xlabel('Epochs', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Learning rate', fontsize=14, fontweight='bold')\n",
    "plt.title(f' Learning rate schedule', fontsize=15, fontweight='bold')\n",
    "\n",
    "x = [x for x in range(0, num_epochs, 10)]\n",
    "y = [0.01, 0.005, 0.000001]\n",
    "ylabel = ['1e-2', '1e-4', '1e-6']\n",
    "plt.xticks(x)\n",
    "plt.yticks(y, ylabel)\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(score, 'r')\n",
    "plt.xlabel('Epochs', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Valid score', fontsize=14, fontweight='bold')\n",
    "plt.title(f'Fold  F1 Score', fontsize=15, fontweight='bold')\n",
    "\n",
    "x = [x for x in range(0, num_epochs, 10)]\n",
    "\n",
    "plt.show()\n",
    "time.sleep(5)\n",
    "plt.close()\n",
    "\n",
    "\n",
    "print(\"train finish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
