{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import time\n",
    "\n",
    "import PIL\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import argparse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, data_frame: pd.DataFrame, root_dir: str, transform=None):\n",
    "        self.data_frame = data_frame\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = dict()\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_name = str(self.data_frame.iloc[idx]['id'])\n",
    "        img_path = os.path.join(self.root_dir, img_name+'.jpg')\n",
    "        image = PIL.Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        tag_name = self.data_frame.iloc[idx]['class']\n",
    "        \n",
    "        sample['image'] = image\n",
    "        sample['class'] = tag_name\n",
    "        \n",
    "        return sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "                [0.485, 0.456, 0.406], \n",
    "                [0.229, 0.224, 0.225])\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, criterion, epoch ):\n",
    "    \n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    for i, data in enumerate(train_loader):\n",
    "        x = data['image']\n",
    "        emotion = data['class']\n",
    "        x = x.to(device)\n",
    "        emotion = emotion.to(device)\n",
    "\n",
    "        optimizer.zero_grad() \n",
    "\n",
    "        out = model(x)\n",
    "\n",
    "        \n",
    "        loss = criterion(out, emotion)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item() / len(train_loader)\n",
    "        #print(f'epoch is {epoch} | train_loss is {train_loss}')\n",
    "    del x, emotion\n",
    "    torch.cuda.empty_cache()\n",
    "    return train_loss\n",
    "\n",
    "def validation(model, criterion, valid_loader):\n",
    "    \n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    label = []\n",
    "    prediction = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(valid_loader):\n",
    "            x = data['image']\n",
    "            emotion = data['class']\n",
    "            x = x.to(device)\n",
    "            emotion = emotion.to(device)\n",
    "            out = model(x)\n",
    "\n",
    "            \n",
    "            loss = criterion(out, emotion)\n",
    "            \n",
    "            pred = torch.argmax(out,dim=-1)\n",
    "            \n",
    "            val_loss += loss.item() / len(valid_loader)\n",
    "            \n",
    "            label = label + emotion.tolist()\n",
    "            prediction = prediction + pred.detach().cpu().tolist()\n",
    "        del x, emotion\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    val_score = f1_score(label, prediction, average='micro') \n",
    "    \n",
    "    return val_loss, val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(args,num_epochs=60, cv_checkpoint=True, fine_tune=False,\n",
    "                weight_file_name='weight_best.pt', **train_kwargs):\n",
    "    # choose scheduler\n",
    "    lr = args.learning_rate\n",
    "    optimizer = optim.AdamW(model.parameters(),lr = lr,weight_decay = 1e-5)   \n",
    "    scheduler = ReduceLROnPlateau(optimizer, 'min', patience=10, factor=0.9)\n",
    "    \n",
    "    train_result = {}\n",
    "    train_result['weight_file_name'] = weight_file_name\n",
    "    best_epoch = -1\n",
    "    best_score = 0.\n",
    "    lrs = []\n",
    "    score = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        start_time = time.time()\n",
    "\n",
    "        train_loss = train(model, train_loader, optimizer,criterion,epoch)\n",
    "        val_loss, val_score = validation(model, criterion, valid_loader)\n",
    "        score.append(val_score)\n",
    "\n",
    "        if cv_checkpoint:\n",
    "            if val_score > best_score:\n",
    "                best_score = val_score\n",
    "                train_result['best_epoch'] = epoch + 1\n",
    "                train_result['best_score'] = round(best_score, 5)\n",
    "                \n",
    "                torch.save(model.state_dict(), weight_file_name)\n",
    "                print(\"Score is higher than last model .....Saving Model.....\")\n",
    "        else:\n",
    "            if val_loss < best_loss:\n",
    "                best_loss = val_loss\n",
    "                train_result['best_epoch'] = epoch + 1\n",
    "                train_result['best_loss'] = round(best_loss, 5)\n",
    "                \n",
    "                torch.save(model.state_dict(), weight_file_name)\n",
    "        \n",
    "        elapsed = time.time() - start_time\n",
    "        now = time.localtime()\n",
    "        lr = [_['lr'] for _ in optimizer.param_groups]\n",
    "        print(\"Epoch {} - train_loss: {:.4f}  val_loss: {:.4f}  cv_score: {:.4f}  lr: {:.6f}  time: {:.0f}s nowtime: {},{}:{}.{}\".format(\n",
    "                epoch+1, train_loss, val_loss, val_score, lr[0], elapsed,now.tm_mday,now.tm_hour,now.tm_min,now.tm_sec))\n",
    "      \n",
    "        for param_group in optimizer.param_groups:\n",
    "            lrs.append(param_group['lr'])\n",
    "        \n",
    "        # scheduler update\n",
    "        if cv_checkpoint:\n",
    "            scheduler.step(val_score)\n",
    "        else:\n",
    "            scheduler.step(val_loss)\n",
    "       \n",
    "     \n",
    "    return train_result, lrs, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "args = parser.parse_args(\"\")\n",
    "\n",
    "df = pd.read_csv(f'../data/assignment/write.csv')\n",
    "data_dir = '../data/assignment/preprocessed_train/'\n",
    "\n",
    "SEED = 42\n",
    "seed_everything(SEED)\n",
    "args.batch_size = 128\n",
    "args.learning_rate = 0.001\n",
    "args.multi_parallel = True\n",
    "args.num_epochs = 2000\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b3\n",
      "Score is higher than last model .....Saving Model.....\n",
      "Epoch 1 - train_loss: 1.1456  val_loss: 1.9988  cv_score: 0.4410  lr: 0.001000  time: 15s nowtime: 23,17:54.34\n",
      "Score is higher than last model .....Saving Model.....\n",
      "Epoch 2 - train_loss: 0.4722  val_loss: 1.4607  cv_score: 0.6108  lr: 0.001000  time: 16s nowtime: 23,17:54.49\n",
      "Score is higher than last model .....Saving Model.....\n",
      "Epoch 3 - train_loss: 0.2192  val_loss: 1.2587  cv_score: 0.6910  lr: 0.001000  time: 15s nowtime: 23,17:55.5\n",
      "Score is higher than last model .....Saving Model.....\n",
      "Epoch 4 - train_loss: 0.1405  val_loss: 1.2399  cv_score: 0.7547  lr: 0.001000  time: 16s nowtime: 23,17:55.20\n",
      "Epoch 5 - train_loss: 0.0989  val_loss: 1.4821  cv_score: 0.7382  lr: 0.001000  time: 15s nowtime: 23,17:55.35\n",
      "Score is higher than last model .....Saving Model.....\n",
      "Epoch 6 - train_loss: 0.0375  val_loss: 1.4063  cv_score: 0.7594  lr: 0.001000  time: 15s nowtime: 23,17:55.51\n",
      "Score is higher than last model .....Saving Model.....\n",
      "Epoch 7 - train_loss: 0.0382  val_loss: 1.1567  cv_score: 0.7972  lr: 0.001000  time: 16s nowtime: 23,17:56.6\n",
      "Epoch 8 - train_loss: 0.0340  val_loss: 1.5108  cv_score: 0.7524  lr: 0.001000  time: 15s nowtime: 23,17:56.22\n",
      "Epoch 9 - train_loss: 0.0537  val_loss: 1.3637  cv_score: 0.7547  lr: 0.001000  time: 15s nowtime: 23,17:56.37\n",
      "Epoch 10 - train_loss: 0.1081  val_loss: 1.7711  cv_score: 0.7288  lr: 0.001000  time: 15s nowtime: 23,17:56.52\n",
      "Epoch 11 - train_loss: 0.1545  val_loss: 2.1136  cv_score: 0.6745  lr: 0.001000  time: 15s nowtime: 23,17:57.8\n",
      "Epoch 12 - train_loss: 0.0798  val_loss: 1.4940  cv_score: 0.7217  lr: 0.001000  time: 15s nowtime: 23,17:57.23\n",
      "Epoch 13 - train_loss: 0.0655  val_loss: 1.2801  cv_score: 0.7642  lr: 0.000900  time: 15s nowtime: 23,17:57.38\n",
      "Epoch 14 - train_loss: 0.0863  val_loss: 1.6451  cv_score: 0.7288  lr: 0.000900  time: 15s nowtime: 23,17:57.53\n",
      "Epoch 15 - train_loss: 0.0461  val_loss: 1.8281  cv_score: 0.7358  lr: 0.000900  time: 15s nowtime: 23,17:58.9\n",
      "Epoch 16 - train_loss: 0.0295  val_loss: 1.5063  cv_score: 0.7500  lr: 0.000900  time: 15s nowtime: 23,17:58.24\n",
      "Score is higher than last model .....Saving Model.....\n",
      "Epoch 17 - train_loss: 0.0281  val_loss: 1.3454  cv_score: 0.7995  lr: 0.000900  time: 15s nowtime: 23,17:58.40\n",
      "Epoch 18 - train_loss: 0.0567  val_loss: 1.6666  cv_score: 0.7406  lr: 0.000900  time: 15s nowtime: 23,17:58.55\n",
      "Epoch 19 - train_loss: 0.0773  val_loss: 2.3864  cv_score: 0.6038  lr: 0.000900  time: 15s nowtime: 23,17:59.10\n",
      "Epoch 20 - train_loss: 0.0655  val_loss: 1.4955  cv_score: 0.7594  lr: 0.000900  time: 15s nowtime: 23,17:59.26\n",
      "Epoch 21 - train_loss: 0.0509  val_loss: 1.6512  cv_score: 0.7288  lr: 0.000900  time: 15s nowtime: 23,17:59.41\n",
      "Epoch 22 - train_loss: 0.0269  val_loss: 1.3203  cv_score: 0.7618  lr: 0.000900  time: 15s nowtime: 23,17:59.56\n",
      "Epoch 23 - train_loss: 0.0134  val_loss: 1.3533  cv_score: 0.7759  lr: 0.000900  time: 15s nowtime: 23,18:0.12\n",
      "Epoch 24 - train_loss: 0.0128  val_loss: 1.2402  cv_score: 0.7877  lr: 0.000810  time: 15s nowtime: 23,18:0.27\n",
      "Epoch 25 - train_loss: 0.0359  val_loss: 1.6925  cv_score: 0.7099  lr: 0.000810  time: 15s nowtime: 23,18:0.43\n",
      "Epoch 26 - train_loss: 0.0306  val_loss: 1.6012  cv_score: 0.7453  lr: 0.000810  time: 15s nowtime: 23,18:0.58\n",
      "Epoch 27 - train_loss: 0.0125  val_loss: 1.5330  cv_score: 0.7689  lr: 0.000810  time: 15s nowtime: 23,18:1.13\n",
      "Epoch 28 - train_loss: 0.0077  val_loss: 1.2998  cv_score: 0.7995  lr: 0.000810  time: 15s nowtime: 23,18:1.28\n",
      "Epoch 29 - train_loss: 0.0074  val_loss: 1.2330  cv_score: 0.7995  lr: 0.000810  time: 16s nowtime: 23,18:1.44\n",
      "Epoch 30 - train_loss: 0.0087  val_loss: 1.2994  cv_score: 0.7877  lr: 0.000810  time: 15s nowtime: 23,18:1.59\n",
      "Epoch 31 - train_loss: 0.0066  val_loss: 1.3816  cv_score: 0.7807  lr: 0.000810  time: 15s nowtime: 23,18:2.15\n",
      "Epoch 32 - train_loss: 0.0058  val_loss: 1.4282  cv_score: 0.7877  lr: 0.000810  time: 15s nowtime: 23,18:2.30\n",
      "Epoch 33 - train_loss: 0.0024  val_loss: 1.4218  cv_score: 0.7925  lr: 0.000810  time: 15s nowtime: 23,18:2.45\n",
      "Score is higher than last model .....Saving Model.....\n",
      "Epoch 34 - train_loss: 0.0020  val_loss: 1.3947  cv_score: 0.8090  lr: 0.000810  time: 15s nowtime: 23,18:3.1\n",
      "Epoch 35 - train_loss: 0.0024  val_loss: 1.4294  cv_score: 0.7972  lr: 0.000729  time: 15s nowtime: 23,18:3.16\n",
      "Epoch 36 - train_loss: 0.0014  val_loss: 1.4463  cv_score: 0.7925  lr: 0.000729  time: 15s nowtime: 23,18:3.31\n",
      "Epoch 37 - train_loss: 0.0117  val_loss: 1.3695  cv_score: 0.7972  lr: 0.000729  time: 15s nowtime: 23,18:3.47\n",
      "Epoch 38 - train_loss: 0.0091  val_loss: 1.2863  cv_score: 0.7877  lr: 0.000729  time: 15s nowtime: 23,18:4.2\n",
      "Epoch 39 - train_loss: 0.0181  val_loss: 1.1256  cv_score: 0.7807  lr: 0.000729  time: 15s nowtime: 23,18:4.18\n",
      "Epoch 40 - train_loss: 0.0159  val_loss: 1.2032  cv_score: 0.7925  lr: 0.000729  time: 15s nowtime: 23,18:4.33\n",
      "Epoch 41 - train_loss: 0.0084  val_loss: 1.2362  cv_score: 0.7854  lr: 0.000729  time: 15s nowtime: 23,18:4.48\n",
      "Epoch 42 - train_loss: 0.0032  val_loss: 1.2277  cv_score: 0.7972  lr: 0.000729  time: 15s nowtime: 23,18:5.4\n",
      "Epoch 43 - train_loss: 0.0066  val_loss: 1.3035  cv_score: 0.8090  lr: 0.000729  time: 15s nowtime: 23,18:5.19\n",
      "Epoch 44 - train_loss: 0.0088  val_loss: 1.2172  cv_score: 0.8019  lr: 0.000729  time: 15s nowtime: 23,18:5.34\n",
      "Epoch 45 - train_loss: 0.0106  val_loss: 1.2403  cv_score: 0.8042  lr: 0.000729  time: 15s nowtime: 23,18:5.50\n",
      "Epoch 46 - train_loss: 0.0107  val_loss: 1.2960  cv_score: 0.7901  lr: 0.000656  time: 15s nowtime: 23,18:6.5\n",
      "Epoch 47 - train_loss: 0.0052  val_loss: 1.2432  cv_score: 0.7854  lr: 0.000656  time: 15s nowtime: 23,18:6.20\n",
      "Epoch 48 - train_loss: 0.0030  val_loss: 1.2392  cv_score: 0.7877  lr: 0.000656  time: 15s nowtime: 23,18:6.35\n",
      "Epoch 49 - train_loss: 0.0101  val_loss: 1.2595  cv_score: 0.7901  lr: 0.000656  time: 15s nowtime: 23,18:6.51\n",
      "Epoch 50 - train_loss: 0.0081  val_loss: 1.3213  cv_score: 0.7854  lr: 0.000656  time: 15s nowtime: 23,18:7.6\n",
      "Epoch 51 - train_loss: 0.0105  val_loss: 1.3251  cv_score: 0.7759  lr: 0.000656  time: 15s nowtime: 23,18:7.21\n",
      "Epoch 52 - train_loss: 0.0096  val_loss: 1.4641  cv_score: 0.7759  lr: 0.000656  time: 15s nowtime: 23,18:7.37\n",
      "Epoch 53 - train_loss: 0.0179  val_loss: 1.4407  cv_score: 0.7948  lr: 0.000656  time: 15s nowtime: 23,18:7.52\n",
      "Epoch 54 - train_loss: 0.0112  val_loss: 1.6286  cv_score: 0.7547  lr: 0.000656  time: 15s nowtime: 23,18:8.8\n",
      "Epoch 55 - train_loss: 0.0120  val_loss: 1.5826  cv_score: 0.7642  lr: 0.000656  time: 15s nowtime: 23,18:8.23\n",
      "Epoch 56 - train_loss: 0.0368  val_loss: 1.4225  cv_score: 0.7759  lr: 0.000656  time: 15s nowtime: 23,18:8.39\n",
      "Epoch 57 - train_loss: 0.0659  val_loss: 1.6708  cv_score: 0.7382  lr: 0.000590  time: 15s nowtime: 23,18:8.54\n",
      "Epoch 58 - train_loss: 0.0329  val_loss: 1.2881  cv_score: 0.7783  lr: 0.000590  time: 15s nowtime: 23,18:9.9\n",
      "Epoch 59 - train_loss: 0.0155  val_loss: 1.3348  cv_score: 0.7759  lr: 0.000590  time: 15s nowtime: 23,18:9.25\n",
      "Epoch 60 - train_loss: 0.0230  val_loss: 1.8353  cv_score: 0.7382  lr: 0.000590  time: 15s nowtime: 23,18:9.40\n",
      "Epoch 61 - train_loss: 0.0225  val_loss: 1.4530  cv_score: 0.7642  lr: 0.000590  time: 15s nowtime: 23,18:9.55\n",
      "Epoch 62 - train_loss: 0.0216  val_loss: 1.4632  cv_score: 0.7642  lr: 0.000590  time: 16s nowtime: 23,18:10.11\n",
      "Epoch 63 - train_loss: 0.0208  val_loss: 1.3594  cv_score: 0.7830  lr: 0.000590  time: 15s nowtime: 23,18:10.26\n",
      "Epoch 64 - train_loss: 0.0202  val_loss: 1.4073  cv_score: 0.7948  lr: 0.000590  time: 15s nowtime: 23,18:10.42\n",
      "Epoch 65 - train_loss: 0.0068  val_loss: 1.3575  cv_score: 0.7783  lr: 0.000590  time: 15s nowtime: 23,18:10.57\n",
      "Epoch 66 - train_loss: 0.0301  val_loss: 1.2739  cv_score: 0.7783  lr: 0.000590  time: 15s nowtime: 23,18:11.12\n",
      "Epoch 67 - train_loss: 0.0227  val_loss: 1.3173  cv_score: 0.7571  lr: 0.000590  time: 15s nowtime: 23,18:11.28\n",
      "Epoch 68 - train_loss: 0.0174  val_loss: 1.4044  cv_score: 0.7547  lr: 0.000531  time: 15s nowtime: 23,18:11.43\n",
      "Epoch 69 - train_loss: 0.0141  val_loss: 1.7293  cv_score: 0.7689  lr: 0.000531  time: 15s nowtime: 23,18:11.59\n",
      "Epoch 70 - train_loss: 0.0265  val_loss: 1.8430  cv_score: 0.7618  lr: 0.000531  time: 15s nowtime: 23,18:12.14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71 - train_loss: 0.0150  val_loss: 1.6841  cv_score: 0.7807  lr: 0.000531  time: 15s nowtime: 23,18:12.29\n",
      "Epoch 72 - train_loss: 0.0081  val_loss: 1.5826  cv_score: 0.7830  lr: 0.000531  time: 15s nowtime: 23,18:12.45\n",
      "Epoch 73 - train_loss: 0.0061  val_loss: 1.5226  cv_score: 0.7925  lr: 0.000531  time: 15s nowtime: 23,18:13.0\n",
      "Epoch 74 - train_loss: 0.0133  val_loss: 1.4567  cv_score: 0.7995  lr: 0.000531  time: 15s nowtime: 23,18:13.15\n",
      "Epoch 75 - train_loss: 0.0339  val_loss: 2.0356  cv_score: 0.6934  lr: 0.000531  time: 15s nowtime: 23,18:13.31\n",
      "Epoch 76 - train_loss: 0.0320  val_loss: 1.7239  cv_score: 0.7264  lr: 0.000531  time: 15s nowtime: 23,18:13.46\n",
      "Epoch 77 - train_loss: 0.0083  val_loss: 1.3841  cv_score: 0.7783  lr: 0.000531  time: 15s nowtime: 23,18:14.1\n",
      "Epoch 78 - train_loss: 0.0048  val_loss: 1.3489  cv_score: 0.7830  lr: 0.000531  time: 15s nowtime: 23,18:14.17\n",
      "Epoch 79 - train_loss: 0.0017  val_loss: 1.3424  cv_score: 0.7830  lr: 0.000478  time: 15s nowtime: 23,18:14.32\n",
      "Epoch 80 - train_loss: 0.0010  val_loss: 1.3465  cv_score: 0.7901  lr: 0.000478  time: 15s nowtime: 23,18:14.47\n",
      "Epoch 81 - train_loss: 0.0005  val_loss: 1.3379  cv_score: 0.7948  lr: 0.000478  time: 15s nowtime: 23,18:15.2\n",
      "Epoch 82 - train_loss: 0.0049  val_loss: 1.3465  cv_score: 0.7972  lr: 0.000478  time: 15s nowtime: 23,18:15.18\n",
      "Epoch 83 - train_loss: 0.0211  val_loss: 1.6513  cv_score: 0.7571  lr: 0.000478  time: 15s nowtime: 23,18:15.33\n",
      "Epoch 84 - train_loss: 0.0086  val_loss: 1.4784  cv_score: 0.7618  lr: 0.000478  time: 15s nowtime: 23,18:15.48\n",
      "Epoch 85 - train_loss: 0.0244  val_loss: 1.4376  cv_score: 0.7736  lr: 0.000478  time: 15s nowtime: 23,18:16.4\n",
      "Epoch 86 - train_loss: 0.0164  val_loss: 1.5274  cv_score: 0.7830  lr: 0.000478  time: 15s nowtime: 23,18:16.19\n",
      "Epoch 87 - train_loss: 0.0128  val_loss: 1.5075  cv_score: 0.7995  lr: 0.000478  time: 15s nowtime: 23,18:16.34\n",
      "Epoch 88 - train_loss: 0.0122  val_loss: 1.4569  cv_score: 0.7877  lr: 0.000478  time: 15s nowtime: 23,18:16.49\n",
      "Epoch 89 - train_loss: 0.0043  val_loss: 1.3844  cv_score: 0.7901  lr: 0.000478  time: 15s nowtime: 23,18:17.5\n",
      "Epoch 90 - train_loss: 0.0062  val_loss: 1.3096  cv_score: 0.8042  lr: 0.000430  time: 15s nowtime: 23,18:17.20\n",
      "Epoch 91 - train_loss: 0.0016  val_loss: 1.2238  cv_score: 0.8019  lr: 0.000430  time: 15s nowtime: 23,18:17.35\n",
      "Epoch 92 - train_loss: 0.0071  val_loss: 1.1652  cv_score: 0.8066  lr: 0.000430  time: 15s nowtime: 23,18:17.51\n",
      "Epoch 93 - train_loss: 0.0274  val_loss: 1.1323  cv_score: 0.7925  lr: 0.000430  time: 15s nowtime: 23,18:18.6\n",
      "Epoch 94 - train_loss: 0.0020  val_loss: 1.1940  cv_score: 0.8019  lr: 0.000430  time: 15s nowtime: 23,18:18.22\n",
      "Epoch 95 - train_loss: 0.0019  val_loss: 1.2046  cv_score: 0.8019  lr: 0.000430  time: 15s nowtime: 23,18:18.37\n",
      "Epoch 96 - train_loss: 0.0025  val_loss: 1.2282  cv_score: 0.8019  lr: 0.000430  time: 15s nowtime: 23,18:18.52\n",
      "Epoch 97 - train_loss: 0.0011  val_loss: 1.2584  cv_score: 0.8042  lr: 0.000430  time: 15s nowtime: 23,18:19.8\n",
      "Epoch 98 - train_loss: 0.0009  val_loss: 1.2694  cv_score: 0.8042  lr: 0.000430  time: 16s nowtime: 23,18:19.23\n",
      "Epoch 99 - train_loss: 0.0016  val_loss: 1.2704  cv_score: 0.8042  lr: 0.000430  time: 15s nowtime: 23,18:19.39\n",
      "Epoch 100 - train_loss: 0.0009  val_loss: 1.2944  cv_score: 0.8090  lr: 0.000430  time: 15s nowtime: 23,18:19.54\n",
      "Epoch 101 - train_loss: 0.0013  val_loss: 1.3113  cv_score: 0.8090  lr: 0.000387  time: 15s nowtime: 23,18:20.10\n",
      "Epoch 102 - train_loss: 0.0003  val_loss: 1.3111  cv_score: 0.8066  lr: 0.000387  time: 15s nowtime: 23,18:20.25\n",
      "Score is higher than last model .....Saving Model.....\n",
      "Epoch 103 - train_loss: 0.0013  val_loss: 1.3131  cv_score: 0.8137  lr: 0.000387  time: 16s nowtime: 23,18:20.41\n",
      "Epoch 104 - train_loss: 0.0004  val_loss: 1.3049  cv_score: 0.8137  lr: 0.000387  time: 15s nowtime: 23,18:20.56\n",
      "Epoch 105 - train_loss: 0.0007  val_loss: 1.3007  cv_score: 0.8090  lr: 0.000387  time: 16s nowtime: 23,18:21.12\n",
      "Epoch 106 - train_loss: 0.0003  val_loss: 1.3009  cv_score: 0.8090  lr: 0.000387  time: 15s nowtime: 23,18:21.27\n",
      "Epoch 107 - train_loss: 0.0002  val_loss: 1.3343  cv_score: 0.8090  lr: 0.000387  time: 15s nowtime: 23,18:21.42\n",
      "Epoch 108 - train_loss: 0.0001  val_loss: 1.3405  cv_score: 0.8090  lr: 0.000387  time: 15s nowtime: 23,18:21.58\n",
      "Epoch 109 - train_loss: 0.0004  val_loss: 1.3419  cv_score: 0.8113  lr: 0.000387  time: 15s nowtime: 23,18:22.13\n",
      "Epoch 110 - train_loss: 0.0003  val_loss: 1.3412  cv_score: 0.8137  lr: 0.000387  time: 15s nowtime: 23,18:22.29\n",
      "Epoch 111 - train_loss: 0.0001  val_loss: 1.3367  cv_score: 0.8137  lr: 0.000387  time: 15s nowtime: 23,18:22.44\n",
      "Score is higher than last model .....Saving Model.....\n",
      "Epoch 112 - train_loss: 0.0005  val_loss: 1.3412  cv_score: 0.8160  lr: 0.000349  time: 16s nowtime: 23,18:22.59\n",
      "Epoch 113 - train_loss: 0.0003  val_loss: 1.3431  cv_score: 0.8160  lr: 0.000349  time: 15s nowtime: 23,18:23.15\n",
      "Epoch 114 - train_loss: 0.0002  val_loss: 1.3425  cv_score: 0.8137  lr: 0.000349  time: 15s nowtime: 23,18:23.30\n",
      "Epoch 115 - train_loss: 0.0002  val_loss: 1.3438  cv_score: 0.8160  lr: 0.000349  time: 15s nowtime: 23,18:23.46\n",
      "Epoch 116 - train_loss: 0.0031  val_loss: 1.3156  cv_score: 0.8066  lr: 0.000349  time: 15s nowtime: 23,18:24.1\n",
      "Epoch 117 - train_loss: 0.0014  val_loss: 1.2910  cv_score: 0.8066  lr: 0.000349  time: 15s nowtime: 23,18:24.16\n",
      "Epoch 118 - train_loss: 0.0002  val_loss: 1.2789  cv_score: 0.8042  lr: 0.000349  time: 15s nowtime: 23,18:24.32\n",
      "Epoch 119 - train_loss: 0.0006  val_loss: 1.2835  cv_score: 0.8042  lr: 0.000349  time: 15s nowtime: 23,18:24.47\n",
      "Epoch 120 - train_loss: 0.0084  val_loss: 1.2934  cv_score: 0.8042  lr: 0.000349  time: 15s nowtime: 23,18:25.2\n",
      "Epoch 121 - train_loss: 0.0009  val_loss: 1.4504  cv_score: 0.7948  lr: 0.000349  time: 15s nowtime: 23,18:25.18\n",
      "Epoch 122 - train_loss: 0.0088  val_loss: 1.4508  cv_score: 0.7877  lr: 0.000349  time: 15s nowtime: 23,18:25.33\n",
      "Epoch 123 - train_loss: 0.0019  val_loss: 1.4827  cv_score: 0.7807  lr: 0.000314  time: 15s nowtime: 23,18:25.48\n",
      "Epoch 124 - train_loss: 0.0015  val_loss: 1.4597  cv_score: 0.7830  lr: 0.000314  time: 15s nowtime: 23,18:26.4\n",
      "Epoch 125 - train_loss: 0.0022  val_loss: 1.4549  cv_score: 0.7830  lr: 0.000314  time: 15s nowtime: 23,18:26.19\n",
      "Epoch 126 - train_loss: 0.0013  val_loss: 1.5205  cv_score: 0.7830  lr: 0.000314  time: 15s nowtime: 23,18:26.34\n",
      "Epoch 127 - train_loss: 0.0027  val_loss: 1.5004  cv_score: 0.7877  lr: 0.000314  time: 15s nowtime: 23,18:26.50\n",
      "Epoch 128 - train_loss: 0.0003  val_loss: 1.4730  cv_score: 0.7948  lr: 0.000314  time: 15s nowtime: 23,18:27.5\n",
      "Epoch 129 - train_loss: 0.0016  val_loss: 1.4624  cv_score: 0.7925  lr: 0.000314  time: 15s nowtime: 23,18:27.21\n",
      "Epoch 130 - train_loss: 0.0004  val_loss: 1.4896  cv_score: 0.7972  lr: 0.000314  time: 16s nowtime: 23,18:27.36\n",
      "Epoch 131 - train_loss: 0.0021  val_loss: 1.4779  cv_score: 0.7948  lr: 0.000314  time: 15s nowtime: 23,18:27.51\n",
      "Epoch 132 - train_loss: 0.0003  val_loss: 1.5002  cv_score: 0.7948  lr: 0.000314  time: 15s nowtime: 23,18:28.7\n",
      "Epoch 133 - train_loss: 0.0011  val_loss: 1.4811  cv_score: 0.7995  lr: 0.000314  time: 15s nowtime: 23,18:28.22\n",
      "Epoch 134 - train_loss: 0.0003  val_loss: 1.4681  cv_score: 0.7948  lr: 0.000282  time: 15s nowtime: 23,18:28.38\n",
      "Epoch 135 - train_loss: 0.0002  val_loss: 1.4651  cv_score: 0.7972  lr: 0.000282  time: 15s nowtime: 23,18:28.53\n",
      "Epoch 136 - train_loss: 0.0002  val_loss: 1.4651  cv_score: 0.7948  lr: 0.000282  time: 16s nowtime: 23,18:29.8\n",
      "Epoch 137 - train_loss: 0.0013  val_loss: 1.4626  cv_score: 0.8042  lr: 0.000282  time: 15s nowtime: 23,18:29.24\n",
      "Epoch 138 - train_loss: 0.0004  val_loss: 1.4800  cv_score: 0.8066  lr: 0.000282  time: 15s nowtime: 23,18:29.39\n",
      "Epoch 139 - train_loss: 0.0008  val_loss: 1.4773  cv_score: 0.8042  lr: 0.000282  time: 15s nowtime: 23,18:29.54\n",
      "Epoch 140 - train_loss: 0.0016  val_loss: 1.5005  cv_score: 0.8066  lr: 0.000282  time: 15s nowtime: 23,18:30.10\n",
      "Epoch 141 - train_loss: 0.0008  val_loss: 1.5332  cv_score: 0.7995  lr: 0.000282  time: 15s nowtime: 23,18:30.25\n",
      "Epoch 142 - train_loss: 0.0002  val_loss: 1.5633  cv_score: 0.7972  lr: 0.000282  time: 15s nowtime: 23,18:30.40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 143 - train_loss: 0.0022  val_loss: 1.5141  cv_score: 0.8066  lr: 0.000282  time: 15s nowtime: 23,18:30.56\n",
      "Epoch 144 - train_loss: 0.0008  val_loss: 1.4822  cv_score: 0.8066  lr: 0.000282  time: 15s nowtime: 23,18:31.11\n",
      "Epoch 145 - train_loss: 0.0003  val_loss: 1.4686  cv_score: 0.8042  lr: 0.000254  time: 15s nowtime: 23,18:31.27\n",
      "Epoch 146 - train_loss: 0.0009  val_loss: 1.4424  cv_score: 0.8019  lr: 0.000254  time: 15s nowtime: 23,18:31.42\n",
      "Epoch 147 - train_loss: 0.0002  val_loss: 1.4361  cv_score: 0.8066  lr: 0.000254  time: 15s nowtime: 23,18:31.57\n",
      "Epoch 148 - train_loss: 0.0001  val_loss: 1.4439  cv_score: 0.8066  lr: 0.000254  time: 15s nowtime: 23,18:32.13\n",
      "Epoch 149 - train_loss: 0.0001  val_loss: 1.4515  cv_score: 0.8090  lr: 0.000254  time: 15s nowtime: 23,18:32.28\n",
      "Score is higher than last model .....Saving Model.....\n",
      "Epoch 150 - train_loss: 0.0008  val_loss: 1.4485  cv_score: 0.8184  lr: 0.000254  time: 15s nowtime: 23,18:32.44\n",
      "Epoch 151 - train_loss: 0.0001  val_loss: 1.4596  cv_score: 0.8066  lr: 0.000254  time: 15s nowtime: 23,18:32.59\n",
      "Epoch 152 - train_loss: 0.0006  val_loss: 1.4657  cv_score: 0.8066  lr: 0.000254  time: 16s nowtime: 23,18:33.15\n",
      "Epoch 153 - train_loss: 0.0001  val_loss: 1.4584  cv_score: 0.7995  lr: 0.000254  time: 15s nowtime: 23,18:33.30\n",
      "Epoch 154 - train_loss: 0.0002  val_loss: 1.4614  cv_score: 0.7972  lr: 0.000254  time: 15s nowtime: 23,18:33.45\n",
      "Epoch 155 - train_loss: 0.0001  val_loss: 1.4647  cv_score: 0.7948  lr: 0.000254  time: 15s nowtime: 23,18:34.1\n",
      "Epoch 156 - train_loss: 0.0001  val_loss: 1.4667  cv_score: 0.7948  lr: 0.000229  time: 16s nowtime: 23,18:34.16\n",
      "Epoch 157 - train_loss: 0.0001  val_loss: 1.4638  cv_score: 0.7948  lr: 0.000229  time: 16s nowtime: 23,18:34.32\n",
      "Epoch 158 - train_loss: 0.0001  val_loss: 1.4647  cv_score: 0.7948  lr: 0.000229  time: 16s nowtime: 23,18:34.48\n",
      "Epoch 159 - train_loss: 0.0003  val_loss: 1.4633  cv_score: 0.7972  lr: 0.000229  time: 15s nowtime: 23,18:35.3\n",
      "Epoch 160 - train_loss: 0.0001  val_loss: 1.4524  cv_score: 0.8019  lr: 0.000229  time: 15s nowtime: 23,18:35.19\n",
      "Epoch 161 - train_loss: 0.0001  val_loss: 1.4496  cv_score: 0.8042  lr: 0.000229  time: 15s nowtime: 23,18:35.34\n",
      "Epoch 162 - train_loss: 0.0001  val_loss: 1.4459  cv_score: 0.8042  lr: 0.000229  time: 15s nowtime: 23,18:35.49\n",
      "Epoch 163 - train_loss: 0.0006  val_loss: 1.4309  cv_score: 0.8090  lr: 0.000229  time: 15s nowtime: 23,18:36.5\n",
      "Epoch 164 - train_loss: 0.0000  val_loss: 1.4190  cv_score: 0.8090  lr: 0.000229  time: 16s nowtime: 23,18:36.20\n",
      "Epoch 165 - train_loss: 0.0001  val_loss: 1.4187  cv_score: 0.8090  lr: 0.000229  time: 15s nowtime: 23,18:36.36\n",
      "Epoch 166 - train_loss: 0.0006  val_loss: 1.4380  cv_score: 0.8137  lr: 0.000229  time: 15s nowtime: 23,18:36.51\n",
      "Epoch 167 - train_loss: 0.0001  val_loss: 1.4565  cv_score: 0.8160  lr: 0.000206  time: 16s nowtime: 23,18:37.7\n",
      "Epoch 168 - train_loss: 0.0001  val_loss: 1.4626  cv_score: 0.8184  lr: 0.000206  time: 15s nowtime: 23,18:37.22\n",
      "Epoch 169 - train_loss: 0.0001  val_loss: 1.4659  cv_score: 0.8184  lr: 0.000206  time: 15s nowtime: 23,18:37.37\n",
      "Epoch 170 - train_loss: 0.0003  val_loss: 1.4620  cv_score: 0.8113  lr: 0.000206  time: 15s nowtime: 23,18:37.52\n",
      "Epoch 171 - train_loss: 0.0001  val_loss: 1.4624  cv_score: 0.8137  lr: 0.000206  time: 15s nowtime: 23,18:38.8\n",
      "Epoch 172 - train_loss: 0.0001  val_loss: 1.4628  cv_score: 0.8160  lr: 0.000206  time: 15s nowtime: 23,18:38.23\n",
      "Epoch 173 - train_loss: 0.0020  val_loss: 1.4689  cv_score: 0.8090  lr: 0.000206  time: 15s nowtime: 23,18:38.38\n",
      "Epoch 174 - train_loss: 0.0002  val_loss: 1.4740  cv_score: 0.8090  lr: 0.000206  time: 15s nowtime: 23,18:38.54\n",
      "Epoch 175 - train_loss: 0.0003  val_loss: 1.4737  cv_score: 0.8042  lr: 0.000206  time: 15s nowtime: 23,18:39.9\n",
      "Epoch 176 - train_loss: 0.0008  val_loss: 1.4628  cv_score: 0.8019  lr: 0.000206  time: 15s nowtime: 23,18:39.24\n",
      "Epoch 177 - train_loss: 0.0019  val_loss: 1.4063  cv_score: 0.8090  lr: 0.000206  time: 15s nowtime: 23,18:39.40\n",
      "Epoch 178 - train_loss: 0.0001  val_loss: 1.4472  cv_score: 0.7995  lr: 0.000185  time: 15s nowtime: 23,18:39.55\n",
      "Epoch 179 - train_loss: 0.0005  val_loss: 1.4580  cv_score: 0.7972  lr: 0.000185  time: 15s nowtime: 23,18:40.11\n",
      "Epoch 180 - train_loss: 0.0006  val_loss: 1.4494  cv_score: 0.7972  lr: 0.000185  time: 15s nowtime: 23,18:40.26\n",
      "Epoch 181 - train_loss: 0.0007  val_loss: 1.4225  cv_score: 0.8019  lr: 0.000185  time: 15s nowtime: 23,18:40.41\n",
      "Epoch 182 - train_loss: 0.0014  val_loss: 1.4107  cv_score: 0.8042  lr: 0.000185  time: 15s nowtime: 23,18:40.57\n",
      "Epoch 183 - train_loss: 0.0002  val_loss: 1.4301  cv_score: 0.8042  lr: 0.000185  time: 15s nowtime: 23,18:41.12\n",
      "Epoch 184 - train_loss: 0.0002  val_loss: 1.4266  cv_score: 0.8066  lr: 0.000185  time: 15s nowtime: 23,18:41.27\n",
      "Epoch 185 - train_loss: 0.0008  val_loss: 1.4114  cv_score: 0.8066  lr: 0.000185  time: 15s nowtime: 23,18:41.43\n",
      "Epoch 186 - train_loss: 0.0086  val_loss: 1.3953  cv_score: 0.8066  lr: 0.000185  time: 15s nowtime: 23,18:41.58\n",
      "Epoch 187 - train_loss: 0.0001  val_loss: 1.4276  cv_score: 0.8090  lr: 0.000185  time: 15s nowtime: 23,18:42.13\n",
      "Epoch 188 - train_loss: 0.0020  val_loss: 1.4460  cv_score: 0.8066  lr: 0.000185  time: 15s nowtime: 23,18:42.29\n",
      "Epoch 189 - train_loss: 0.0021  val_loss: 1.4728  cv_score: 0.8042  lr: 0.000167  time: 15s nowtime: 23,18:42.44\n",
      "Epoch 190 - train_loss: 0.0001  val_loss: 1.4750  cv_score: 0.8019  lr: 0.000167  time: 16s nowtime: 23,18:43.0\n",
      "Epoch 191 - train_loss: 0.0016  val_loss: 1.4665  cv_score: 0.7995  lr: 0.000167  time: 15s nowtime: 23,18:43.15\n",
      "Epoch 192 - train_loss: 0.0001  val_loss: 1.4677  cv_score: 0.7948  lr: 0.000167  time: 15s nowtime: 23,18:43.30\n",
      "Epoch 193 - train_loss: 0.0003  val_loss: 1.4708  cv_score: 0.7948  lr: 0.000167  time: 15s nowtime: 23,18:43.45\n",
      "Epoch 194 - train_loss: 0.0046  val_loss: 1.4838  cv_score: 0.7972  lr: 0.000167  time: 15s nowtime: 23,18:44.1\n",
      "Epoch 195 - train_loss: 0.0007  val_loss: 1.5745  cv_score: 0.7995  lr: 0.000167  time: 15s nowtime: 23,18:44.16\n",
      "Epoch 196 - train_loss: 0.0017  val_loss: 1.6173  cv_score: 0.8042  lr: 0.000167  time: 15s nowtime: 23,18:44.32\n",
      "Epoch 197 - train_loss: 0.0011  val_loss: 1.6720  cv_score: 0.7995  lr: 0.000167  time: 15s nowtime: 23,18:44.47\n",
      "Epoch 198 - train_loss: 0.0006  val_loss: 1.7034  cv_score: 0.7948  lr: 0.000167  time: 16s nowtime: 23,18:45.2\n",
      "Epoch 199 - train_loss: 0.0001  val_loss: 1.7061  cv_score: 0.8042  lr: 0.000167  time: 15s nowtime: 23,18:45.18\n",
      "Epoch 200 - train_loss: 0.0001  val_loss: 1.6969  cv_score: 0.8042  lr: 0.000150  time: 15s nowtime: 23,18:45.33\n",
      "Epoch 201 - train_loss: 0.0004  val_loss: 1.6534  cv_score: 0.8090  lr: 0.000150  time: 15s nowtime: 23,18:45.49\n",
      "Epoch 202 - train_loss: 0.0001  val_loss: 1.6377  cv_score: 0.8066  lr: 0.000150  time: 15s nowtime: 23,18:46.4\n",
      "Epoch 203 - train_loss: 0.0001  val_loss: 1.6328  cv_score: 0.8066  lr: 0.000150  time: 15s nowtime: 23,18:46.19\n",
      "Epoch 204 - train_loss: 0.0001  val_loss: 1.6292  cv_score: 0.8066  lr: 0.000150  time: 15s nowtime: 23,18:46.35\n",
      "Epoch 205 - train_loss: 0.0001  val_loss: 1.6262  cv_score: 0.8066  lr: 0.000150  time: 15s nowtime: 23,18:46.50\n",
      "Epoch 206 - train_loss: 0.0001  val_loss: 1.6255  cv_score: 0.8066  lr: 0.000150  time: 15s nowtime: 23,18:47.5\n",
      "Epoch 207 - train_loss: 0.0009  val_loss: 1.6180  cv_score: 0.8066  lr: 0.000150  time: 15s nowtime: 23,18:47.21\n",
      "Epoch 208 - train_loss: 0.0001  val_loss: 1.5896  cv_score: 0.8090  lr: 0.000150  time: 15s nowtime: 23,18:47.36\n",
      "Epoch 209 - train_loss: 0.0001  val_loss: 1.5854  cv_score: 0.8066  lr: 0.000150  time: 15s nowtime: 23,18:47.51\n",
      "Epoch 210 - train_loss: 0.0046  val_loss: 1.5806  cv_score: 0.8090  lr: 0.000150  time: 15s nowtime: 23,18:48.7\n",
      "Epoch 211 - train_loss: 0.0003  val_loss: 1.6622  cv_score: 0.7854  lr: 0.000135  time: 15s nowtime: 23,18:48.22\n",
      "Epoch 212 - train_loss: 0.0084  val_loss: 1.6824  cv_score: 0.7877  lr: 0.000135  time: 15s nowtime: 23,18:48.37\n",
      "Epoch 213 - train_loss: 0.0032  val_loss: 1.7352  cv_score: 0.7854  lr: 0.000135  time: 15s nowtime: 23,18:48.53\n",
      "Epoch 214 - train_loss: 0.0063  val_loss: 1.6725  cv_score: 0.7877  lr: 0.000135  time: 15s nowtime: 23,18:49.8\n",
      "Epoch 215 - train_loss: 0.0030  val_loss: 1.6557  cv_score: 0.7807  lr: 0.000135  time: 15s nowtime: 23,18:49.23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 216 - train_loss: 0.0008  val_loss: 1.6355  cv_score: 0.7830  lr: 0.000135  time: 15s nowtime: 23,18:49.38\n",
      "Epoch 217 - train_loss: 0.0001  val_loss: 1.6163  cv_score: 0.7948  lr: 0.000135  time: 15s nowtime: 23,18:49.54\n",
      "Epoch 218 - train_loss: 0.0002  val_loss: 1.5996  cv_score: 0.7995  lr: 0.000135  time: 15s nowtime: 23,18:50.9\n",
      "Epoch 219 - train_loss: 0.0018  val_loss: 1.5695  cv_score: 0.8090  lr: 0.000135  time: 15s nowtime: 23,18:50.24\n",
      "Epoch 220 - train_loss: 0.0003  val_loss: 1.5676  cv_score: 0.8113  lr: 0.000135  time: 15s nowtime: 23,18:50.40\n",
      "Epoch 221 - train_loss: 0.0006  val_loss: 1.5629  cv_score: 0.8090  lr: 0.000135  time: 15s nowtime: 23,18:50.55\n",
      "Epoch 222 - train_loss: 0.0005  val_loss: 1.5422  cv_score: 0.8066  lr: 0.000122  time: 15s nowtime: 23,18:51.10\n",
      "Epoch 223 - train_loss: 0.0002  val_loss: 1.5377  cv_score: 0.8066  lr: 0.000122  time: 15s nowtime: 23,18:51.26\n",
      "Epoch 224 - train_loss: 0.0008  val_loss: 1.5310  cv_score: 0.8042  lr: 0.000122  time: 15s nowtime: 23,18:51.41\n",
      "Epoch 225 - train_loss: 0.0002  val_loss: 1.5101  cv_score: 0.8090  lr: 0.000122  time: 15s nowtime: 23,18:51.56\n",
      "Epoch 226 - train_loss: 0.0001  val_loss: 1.5089  cv_score: 0.8090  lr: 0.000122  time: 15s nowtime: 23,18:52.12\n",
      "Epoch 227 - train_loss: 0.0001  val_loss: 1.5089  cv_score: 0.8090  lr: 0.000122  time: 15s nowtime: 23,18:52.27\n",
      "Epoch 228 - train_loss: 0.0001  val_loss: 1.5096  cv_score: 0.8090  lr: 0.000122  time: 15s nowtime: 23,18:52.43\n",
      "Epoch 229 - train_loss: 0.0001  val_loss: 1.5109  cv_score: 0.8090  lr: 0.000122  time: 15s nowtime: 23,18:52.58\n",
      "Epoch 230 - train_loss: 0.0011  val_loss: 1.5086  cv_score: 0.8113  lr: 0.000122  time: 15s nowtime: 23,18:53.13\n",
      "Epoch 231 - train_loss: 0.0003  val_loss: 1.5087  cv_score: 0.8090  lr: 0.000122  time: 15s nowtime: 23,18:53.28\n",
      "Epoch 232 - train_loss: 0.0006  val_loss: 1.5113  cv_score: 0.8090  lr: 0.000122  time: 15s nowtime: 23,18:53.44\n",
      "Epoch 233 - train_loss: 0.0001  val_loss: 1.5118  cv_score: 0.8066  lr: 0.000109  time: 15s nowtime: 23,18:53.59\n",
      "Epoch 234 - train_loss: 0.0001  val_loss: 1.5143  cv_score: 0.8042  lr: 0.000109  time: 15s nowtime: 23,18:54.15\n",
      "Epoch 235 - train_loss: 0.0002  val_loss: 1.5087  cv_score: 0.8042  lr: 0.000109  time: 15s nowtime: 23,18:54.30\n",
      "Epoch 236 - train_loss: 0.0002  val_loss: 1.5062  cv_score: 0.8042  lr: 0.000109  time: 15s nowtime: 23,18:54.45\n",
      "Epoch 237 - train_loss: 0.0001  val_loss: 1.5058  cv_score: 0.8042  lr: 0.000109  time: 15s nowtime: 23,18:55.1\n",
      "Epoch 238 - train_loss: 0.0002  val_loss: 1.5050  cv_score: 0.8042  lr: 0.000109  time: 16s nowtime: 23,18:55.16\n",
      "Epoch 239 - train_loss: 0.0041  val_loss: 1.4979  cv_score: 0.8019  lr: 0.000109  time: 15s nowtime: 23,18:55.31\n",
      "Epoch 240 - train_loss: 0.0003  val_loss: 1.4332  cv_score: 0.8019  lr: 0.000109  time: 15s nowtime: 23,18:55.47\n",
      "Epoch 241 - train_loss: 0.0007  val_loss: 1.4313  cv_score: 0.8090  lr: 0.000109  time: 15s nowtime: 23,18:56.2\n",
      "Epoch 242 - train_loss: 0.0002  val_loss: 1.4294  cv_score: 0.8090  lr: 0.000109  time: 15s nowtime: 23,18:56.18\n",
      "Epoch 243 - train_loss: 0.0002  val_loss: 1.4283  cv_score: 0.8066  lr: 0.000109  time: 15s nowtime: 23,18:56.33\n",
      "Epoch 244 - train_loss: 0.0001  val_loss: 1.4279  cv_score: 0.8066  lr: 0.000098  time: 15s nowtime: 23,18:56.48\n",
      "Epoch 245 - train_loss: 0.0004  val_loss: 1.4214  cv_score: 0.7995  lr: 0.000098  time: 15s nowtime: 23,18:57.3\n",
      "Epoch 246 - train_loss: 0.0004  val_loss: 1.4197  cv_score: 0.7972  lr: 0.000098  time: 15s nowtime: 23,18:57.19\n",
      "Epoch 247 - train_loss: 0.0001  val_loss: 1.4234  cv_score: 0.7995  lr: 0.000098  time: 15s nowtime: 23,18:57.34\n",
      "Epoch 248 - train_loss: 0.0003  val_loss: 1.4267  cv_score: 0.8042  lr: 0.000098  time: 15s nowtime: 23,18:57.49\n",
      "Epoch 249 - train_loss: 0.0002  val_loss: 1.4310  cv_score: 0.8042  lr: 0.000098  time: 15s nowtime: 23,18:58.5\n",
      "Epoch 250 - train_loss: 0.0002  val_loss: 1.4318  cv_score: 0.8042  lr: 0.000098  time: 16s nowtime: 23,18:58.20\n",
      "Epoch 251 - train_loss: 0.0004  val_loss: 1.4280  cv_score: 0.8019  lr: 0.000098  time: 15s nowtime: 23,18:58.35\n",
      "Epoch 252 - train_loss: 0.0001  val_loss: 1.4252  cv_score: 0.8019  lr: 0.000098  time: 16s nowtime: 23,18:58.51\n",
      "Epoch 253 - train_loss: 0.0002  val_loss: 1.4201  cv_score: 0.8019  lr: 0.000098  time: 15s nowtime: 23,18:59.6\n",
      "Epoch 254 - train_loss: 0.0002  val_loss: 1.4200  cv_score: 0.8042  lr: 0.000098  time: 15s nowtime: 23,18:59.22\n",
      "Epoch 255 - train_loss: 0.0003  val_loss: 1.4218  cv_score: 0.8066  lr: 0.000089  time: 15s nowtime: 23,18:59.37\n",
      "Epoch 256 - train_loss: 0.0050  val_loss: 1.4160  cv_score: 0.8042  lr: 0.000089  time: 15s nowtime: 23,18:59.52\n",
      "Epoch 257 - train_loss: 0.0003  val_loss: 1.4253  cv_score: 0.7948  lr: 0.000089  time: 15s nowtime: 23,19:0.8\n",
      "Epoch 258 - train_loss: 0.0004  val_loss: 1.4353  cv_score: 0.7972  lr: 0.000089  time: 15s nowtime: 23,19:0.23\n",
      "Epoch 259 - train_loss: 0.0002  val_loss: 1.4374  cv_score: 0.7972  lr: 0.000089  time: 15s nowtime: 23,19:0.39\n",
      "Epoch 260 - train_loss: 0.0006  val_loss: 1.4230  cv_score: 0.7948  lr: 0.000089  time: 15s nowtime: 23,19:0.54\n",
      "Epoch 261 - train_loss: 0.0002  val_loss: 1.4171  cv_score: 0.7948  lr: 0.000089  time: 16s nowtime: 23,19:1.10\n",
      "Epoch 262 - train_loss: 0.0002  val_loss: 1.4173  cv_score: 0.7995  lr: 0.000089  time: 15s nowtime: 23,19:1.25\n",
      "Epoch 263 - train_loss: 0.0003  val_loss: 1.4323  cv_score: 0.8042  lr: 0.000089  time: 15s nowtime: 23,19:1.41\n",
      "Epoch 264 - train_loss: 0.0005  val_loss: 1.4374  cv_score: 0.8042  lr: 0.000089  time: 15s nowtime: 23,19:1.56\n",
      "Epoch 265 - train_loss: 0.0003  val_loss: 1.4406  cv_score: 0.7995  lr: 0.000089  time: 15s nowtime: 23,19:2.12\n",
      "Epoch 266 - train_loss: 0.0001  val_loss: 1.4411  cv_score: 0.8042  lr: 0.000080  time: 15s nowtime: 23,19:2.27\n",
      "Epoch 267 - train_loss: 0.0001  val_loss: 1.4437  cv_score: 0.8042  lr: 0.000080  time: 15s nowtime: 23,19:2.42\n",
      "Epoch 268 - train_loss: 0.0002  val_loss: 1.4408  cv_score: 0.8066  lr: 0.000080  time: 15s nowtime: 23,19:2.57\n",
      "Epoch 269 - train_loss: 0.0003  val_loss: 1.4386  cv_score: 0.8090  lr: 0.000080  time: 16s nowtime: 23,19:3.13\n",
      "Epoch 270 - train_loss: 0.0001  val_loss: 1.4407  cv_score: 0.8090  lr: 0.000080  time: 15s nowtime: 23,19:3.28\n",
      "Epoch 271 - train_loss: 0.0001  val_loss: 1.4404  cv_score: 0.8090  lr: 0.000080  time: 15s nowtime: 23,19:3.43\n",
      "Epoch 272 - train_loss: 0.0000  val_loss: 1.4422  cv_score: 0.8090  lr: 0.000080  time: 15s nowtime: 23,19:3.59\n",
      "Epoch 273 - train_loss: 0.0000  val_loss: 1.4432  cv_score: 0.8090  lr: 0.000080  time: 15s nowtime: 23,19:4.14\n",
      "Epoch 274 - train_loss: 0.0000  val_loss: 1.4425  cv_score: 0.8066  lr: 0.000080  time: 15s nowtime: 23,19:4.30\n",
      "Epoch 275 - train_loss: 0.0008  val_loss: 1.4302  cv_score: 0.8019  lr: 0.000080  time: 15s nowtime: 23,19:4.45\n",
      "Epoch 276 - train_loss: 0.0004  val_loss: 1.4265  cv_score: 0.8019  lr: 0.000080  time: 15s nowtime: 23,19:5.0\n",
      "Epoch 277 - train_loss: 0.0001  val_loss: 1.4237  cv_score: 0.8042  lr: 0.000072  time: 15s nowtime: 23,19:5.16\n",
      "Epoch 278 - train_loss: 0.0003  val_loss: 1.4187  cv_score: 0.8066  lr: 0.000072  time: 15s nowtime: 23,19:5.31\n",
      "Epoch 279 - train_loss: 0.0000  val_loss: 1.4155  cv_score: 0.8113  lr: 0.000072  time: 15s nowtime: 23,19:5.46\n",
      "Epoch 280 - train_loss: 0.0003  val_loss: 1.4159  cv_score: 0.8113  lr: 0.000072  time: 15s nowtime: 23,19:6.2\n",
      "Epoch 281 - train_loss: 0.0000  val_loss: 1.4211  cv_score: 0.8113  lr: 0.000072  time: 15s nowtime: 23,19:6.17\n",
      "Epoch 282 - train_loss: 0.0002  val_loss: 1.4191  cv_score: 0.8090  lr: 0.000072  time: 15s nowtime: 23,19:6.32\n",
      "Epoch 283 - train_loss: 0.0000  val_loss: 1.4145  cv_score: 0.8042  lr: 0.000072  time: 15s nowtime: 23,19:6.48\n",
      "Epoch 284 - train_loss: 0.0001  val_loss: 1.4138  cv_score: 0.8042  lr: 0.000072  time: 16s nowtime: 23,19:7.3\n",
      "Epoch 285 - train_loss: 0.0000  val_loss: 1.4145  cv_score: 0.8019  lr: 0.000072  time: 15s nowtime: 23,19:7.18\n",
      "Epoch 286 - train_loss: 0.0001  val_loss: 1.4151  cv_score: 0.8019  lr: 0.000072  time: 15s nowtime: 23,19:7.34\n",
      "Epoch 287 - train_loss: 0.0001  val_loss: 1.4153  cv_score: 0.8019  lr: 0.000072  time: 15s nowtime: 23,19:7.49\n",
      "Epoch 288 - train_loss: 0.0000  val_loss: 1.4142  cv_score: 0.8019  lr: 0.000065  time: 15s nowtime: 23,19:8.4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 289 - train_loss: 0.0000  val_loss: 1.4148  cv_score: 0.8042  lr: 0.000065  time: 15s nowtime: 23,19:8.20\n",
      "Epoch 290 - train_loss: 0.0001  val_loss: 1.4134  cv_score: 0.8042  lr: 0.000065  time: 15s nowtime: 23,19:8.35\n",
      "Epoch 291 - train_loss: 0.0001  val_loss: 1.4130  cv_score: 0.8042  lr: 0.000065  time: 15s nowtime: 23,19:8.50\n",
      "Epoch 292 - train_loss: 0.0001  val_loss: 1.4159  cv_score: 0.8066  lr: 0.000065  time: 15s nowtime: 23,19:9.6\n",
      "Epoch 293 - train_loss: 0.0025  val_loss: 1.4166  cv_score: 0.8090  lr: 0.000065  time: 15s nowtime: 23,19:9.21\n",
      "Epoch 294 - train_loss: 0.0058  val_loss: 1.4387  cv_score: 0.8042  lr: 0.000065  time: 15s nowtime: 23,19:9.36\n",
      "Epoch 295 - train_loss: 0.0021  val_loss: 1.4565  cv_score: 0.7995  lr: 0.000065  time: 15s nowtime: 23,19:9.52\n",
      "Epoch 296 - train_loss: 0.0002  val_loss: 1.4572  cv_score: 0.7948  lr: 0.000065  time: 15s nowtime: 23,19:10.7\n",
      "Epoch 297 - train_loss: 0.0015  val_loss: 1.4585  cv_score: 0.7948  lr: 0.000065  time: 15s nowtime: 23,19:10.22\n",
      "Epoch 298 - train_loss: 0.0005  val_loss: 1.4533  cv_score: 0.7925  lr: 0.000065  time: 15s nowtime: 23,19:10.37\n",
      "Epoch 299 - train_loss: 0.0001  val_loss: 1.4398  cv_score: 0.7972  lr: 0.000058  time: 15s nowtime: 23,19:10.53\n",
      "Epoch 300 - train_loss: 0.0003  val_loss: 1.4298  cv_score: 0.7972  lr: 0.000058  time: 15s nowtime: 23,19:11.8\n",
      "Epoch 301 - train_loss: 0.0001  val_loss: 1.4216  cv_score: 0.7995  lr: 0.000058  time: 15s nowtime: 23,19:11.24\n",
      "Epoch 302 - train_loss: 0.0002  val_loss: 1.4210  cv_score: 0.7995  lr: 0.000058  time: 15s nowtime: 23,19:11.39\n",
      "Epoch 303 - train_loss: 0.0001  val_loss: 1.4200  cv_score: 0.7995  lr: 0.000058  time: 15s nowtime: 23,19:11.54\n",
      "Epoch 304 - train_loss: 0.0005  val_loss: 1.4130  cv_score: 0.8019  lr: 0.000058  time: 15s nowtime: 23,19:12.10\n",
      "Epoch 305 - train_loss: 0.0001  val_loss: 1.4068  cv_score: 0.8019  lr: 0.000058  time: 15s nowtime: 23,19:12.25\n",
      "Epoch 306 - train_loss: 0.0001  val_loss: 1.4048  cv_score: 0.8019  lr: 0.000058  time: 15s nowtime: 23,19:12.40\n",
      "Epoch 307 - train_loss: 0.0001  val_loss: 1.4051  cv_score: 0.8019  lr: 0.000058  time: 15s nowtime: 23,19:12.56\n",
      "Epoch 308 - train_loss: 0.0000  val_loss: 1.4053  cv_score: 0.7995  lr: 0.000058  time: 15s nowtime: 23,19:13.11\n",
      "Epoch 309 - train_loss: 0.0000  val_loss: 1.4047  cv_score: 0.7995  lr: 0.000058  time: 15s nowtime: 23,19:13.26\n",
      "Epoch 310 - train_loss: 0.0000  val_loss: 1.4034  cv_score: 0.7995  lr: 0.000052  time: 16s nowtime: 23,19:13.42\n",
      "Epoch 311 - train_loss: 0.0002  val_loss: 1.4049  cv_score: 0.7972  lr: 0.000052  time: 15s nowtime: 23,19:13.57\n",
      "Epoch 312 - train_loss: 0.0005  val_loss: 1.4054  cv_score: 0.8066  lr: 0.000052  time: 15s nowtime: 23,19:14.12\n",
      "Epoch 313 - train_loss: 0.0001  val_loss: 1.4076  cv_score: 0.8090  lr: 0.000052  time: 15s nowtime: 23,19:14.28\n",
      "Epoch 314 - train_loss: 0.0001  val_loss: 1.4065  cv_score: 0.8066  lr: 0.000052  time: 15s nowtime: 23,19:14.43\n",
      "Epoch 315 - train_loss: 0.0001  val_loss: 1.4057  cv_score: 0.8090  lr: 0.000052  time: 15s nowtime: 23,19:14.58\n",
      "Epoch 316 - train_loss: 0.0001  val_loss: 1.4065  cv_score: 0.8090  lr: 0.000052  time: 15s nowtime: 23,19:15.14\n",
      "Epoch 317 - train_loss: 0.0014  val_loss: 1.4210  cv_score: 0.8066  lr: 0.000052  time: 15s nowtime: 23,19:15.29\n",
      "Epoch 318 - train_loss: 0.0000  val_loss: 1.4266  cv_score: 0.8090  lr: 0.000052  time: 15s nowtime: 23,19:15.44\n",
      "Epoch 319 - train_loss: 0.0000  val_loss: 1.4267  cv_score: 0.8090  lr: 0.000052  time: 15s nowtime: 23,19:16.0\n",
      "Epoch 320 - train_loss: 0.0001  val_loss: 1.4240  cv_score: 0.8113  lr: 0.000052  time: 15s nowtime: 23,19:16.15\n",
      "Epoch 321 - train_loss: 0.0002  val_loss: 1.4227  cv_score: 0.8137  lr: 0.000047  time: 15s nowtime: 23,19:16.30\n",
      "Epoch 322 - train_loss: 0.0000  val_loss: 1.4216  cv_score: 0.8113  lr: 0.000047  time: 15s nowtime: 23,19:16.46\n",
      "Epoch 323 - train_loss: 0.0001  val_loss: 1.4220  cv_score: 0.8113  lr: 0.000047  time: 15s nowtime: 23,19:17.1\n",
      "Epoch 324 - train_loss: 0.0000  val_loss: 1.4213  cv_score: 0.8137  lr: 0.000047  time: 15s nowtime: 23,19:17.16\n",
      "Epoch 325 - train_loss: 0.0000  val_loss: 1.4213  cv_score: 0.8137  lr: 0.000047  time: 15s nowtime: 23,19:17.31\n",
      "Epoch 326 - train_loss: 0.0001  val_loss: 1.4204  cv_score: 0.8137  lr: 0.000047  time: 15s nowtime: 23,19:17.47\n",
      "Epoch 327 - train_loss: 0.0006  val_loss: 1.4230  cv_score: 0.8137  lr: 0.000047  time: 15s nowtime: 23,19:18.2\n",
      "Epoch 328 - train_loss: 0.0000  val_loss: 1.4404  cv_score: 0.8160  lr: 0.000047  time: 16s nowtime: 23,19:18.18\n",
      "Epoch 329 - train_loss: 0.0000  val_loss: 1.4444  cv_score: 0.8090  lr: 0.000047  time: 15s nowtime: 23,19:18.33\n",
      "Epoch 330 - train_loss: 0.0000  val_loss: 1.4436  cv_score: 0.8137  lr: 0.000047  time: 15s nowtime: 23,19:18.48\n",
      "Epoch 331 - train_loss: 0.0000  val_loss: 1.4414  cv_score: 0.8137  lr: 0.000047  time: 15s nowtime: 23,19:19.4\n",
      "Epoch 332 - train_loss: 0.0000  val_loss: 1.4387  cv_score: 0.8113  lr: 0.000042  time: 15s nowtime: 23,19:19.19\n",
      "Epoch 333 - train_loss: 0.0000  val_loss: 1.4383  cv_score: 0.8137  lr: 0.000042  time: 15s nowtime: 23,19:19.34\n",
      "Epoch 334 - train_loss: 0.0000  val_loss: 1.4362  cv_score: 0.8137  lr: 0.000042  time: 15s nowtime: 23,19:19.50\n",
      "Epoch 335 - train_loss: 0.0001  val_loss: 1.4342  cv_score: 0.8137  lr: 0.000042  time: 15s nowtime: 23,19:20.5\n",
      "Epoch 336 - train_loss: 0.0000  val_loss: 1.4345  cv_score: 0.8137  lr: 0.000042  time: 15s nowtime: 23,19:20.20\n",
      "Epoch 337 - train_loss: 0.0002  val_loss: 1.4390  cv_score: 0.8137  lr: 0.000042  time: 15s nowtime: 23,19:20.36\n",
      "Epoch 338 - train_loss: 0.0000  val_loss: 1.4397  cv_score: 0.8137  lr: 0.000042  time: 15s nowtime: 23,19:20.51\n",
      "Epoch 339 - train_loss: 0.0000  val_loss: 1.4405  cv_score: 0.8113  lr: 0.000042  time: 15s nowtime: 23,19:21.6\n",
      "Epoch 340 - train_loss: 0.0001  val_loss: 1.4388  cv_score: 0.8137  lr: 0.000042  time: 15s nowtime: 23,19:21.22\n",
      "Epoch 341 - train_loss: 0.0000  val_loss: 1.4401  cv_score: 0.8113  lr: 0.000042  time: 16s nowtime: 23,19:21.37\n",
      "Epoch 342 - train_loss: 0.0001  val_loss: 1.4483  cv_score: 0.8113  lr: 0.000042  time: 15s nowtime: 23,19:21.52\n",
      "Epoch 343 - train_loss: 0.0001  val_loss: 1.4511  cv_score: 0.8137  lr: 0.000038  time: 15s nowtime: 23,19:22.8\n",
      "Epoch 344 - train_loss: 0.0000  val_loss: 1.4513  cv_score: 0.8137  lr: 0.000038  time: 15s nowtime: 23,19:22.23\n",
      "Epoch 345 - train_loss: 0.0000  val_loss: 1.4510  cv_score: 0.8160  lr: 0.000038  time: 15s nowtime: 23,19:22.38\n",
      "Epoch 346 - train_loss: 0.0000  val_loss: 1.4513  cv_score: 0.8160  lr: 0.000038  time: 15s nowtime: 23,19:22.53\n",
      "Epoch 347 - train_loss: 0.0001  val_loss: 1.4508  cv_score: 0.8160  lr: 0.000038  time: 15s nowtime: 23,19:23.9\n",
      "Epoch 348 - train_loss: 0.0000  val_loss: 1.4514  cv_score: 0.8113  lr: 0.000038  time: 15s nowtime: 23,19:23.24\n",
      "Epoch 349 - train_loss: 0.0001  val_loss: 1.4517  cv_score: 0.8137  lr: 0.000038  time: 15s nowtime: 23,19:23.39\n",
      "Epoch 350 - train_loss: 0.0000  val_loss: 1.4516  cv_score: 0.8137  lr: 0.000038  time: 15s nowtime: 23,19:23.54\n",
      "Epoch 351 - train_loss: 0.0000  val_loss: 1.4504  cv_score: 0.8160  lr: 0.000038  time: 15s nowtime: 23,19:24.10\n",
      "Epoch 352 - train_loss: 0.0000  val_loss: 1.4510  cv_score: 0.8160  lr: 0.000038  time: 15s nowtime: 23,19:24.25\n",
      "Epoch 353 - train_loss: 0.0000  val_loss: 1.4511  cv_score: 0.8184  lr: 0.000038  time: 15s nowtime: 23,19:24.40\n",
      "Epoch 354 - train_loss: 0.0001  val_loss: 1.4519  cv_score: 0.8184  lr: 0.000034  time: 15s nowtime: 23,19:24.56\n",
      "Epoch 355 - train_loss: 0.0001  val_loss: 1.4520  cv_score: 0.8184  lr: 0.000034  time: 15s nowtime: 23,19:25.11\n",
      "Epoch 356 - train_loss: 0.0000  val_loss: 1.4512  cv_score: 0.8184  lr: 0.000034  time: 15s nowtime: 23,19:25.26\n",
      "Epoch 357 - train_loss: 0.0000  val_loss: 1.4512  cv_score: 0.8184  lr: 0.000034  time: 15s nowtime: 23,19:25.42\n",
      "Epoch 358 - train_loss: 0.0000  val_loss: 1.4514  cv_score: 0.8184  lr: 0.000034  time: 15s nowtime: 23,19:25.57\n",
      "Score is higher than last model .....Saving Model.....\n",
      "Epoch 359 - train_loss: 0.0001  val_loss: 1.4512  cv_score: 0.8208  lr: 0.000034  time: 15s nowtime: 23,19:26.12\n",
      "Epoch 360 - train_loss: 0.0000  val_loss: 1.4469  cv_score: 0.8160  lr: 0.000034  time: 15s nowtime: 23,19:26.28\n",
      "Epoch 361 - train_loss: 0.0000  val_loss: 1.4478  cv_score: 0.8160  lr: 0.000034  time: 15s nowtime: 23,19:26.43\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 362 - train_loss: 0.0014  val_loss: 1.4499  cv_score: 0.8160  lr: 0.000034  time: 15s nowtime: 23,19:26.58\n",
      "Epoch 363 - train_loss: 0.0000  val_loss: 1.4607  cv_score: 0.8160  lr: 0.000034  time: 15s nowtime: 23,19:27.14\n",
      "Epoch 364 - train_loss: 0.0001  val_loss: 1.4652  cv_score: 0.8137  lr: 0.000034  time: 15s nowtime: 23,19:27.29\n",
      "Epoch 365 - train_loss: 0.0005  val_loss: 1.4646  cv_score: 0.8137  lr: 0.000031  time: 15s nowtime: 23,19:27.44\n",
      "Epoch 366 - train_loss: 0.0001  val_loss: 1.4667  cv_score: 0.8113  lr: 0.000031  time: 15s nowtime: 23,19:27.59\n",
      "Epoch 367 - train_loss: 0.0000  val_loss: 1.4721  cv_score: 0.8113  lr: 0.000031  time: 15s nowtime: 23,19:28.15\n",
      "Epoch 368 - train_loss: 0.0000  val_loss: 1.4732  cv_score: 0.8090  lr: 0.000031  time: 15s nowtime: 23,19:28.30\n",
      "Epoch 369 - train_loss: 0.0000  val_loss: 1.4740  cv_score: 0.8090  lr: 0.000031  time: 16s nowtime: 23,19:28.46\n",
      "Epoch 370 - train_loss: 0.0001  val_loss: 1.4730  cv_score: 0.8113  lr: 0.000031  time: 15s nowtime: 23,19:29.1\n",
      "Epoch 371 - train_loss: 0.0001  val_loss: 1.4721  cv_score: 0.8113  lr: 0.000031  time: 15s nowtime: 23,19:29.16\n",
      "Epoch 372 - train_loss: 0.0002  val_loss: 1.4708  cv_score: 0.8113  lr: 0.000031  time: 15s nowtime: 23,19:29.32\n",
      "Epoch 373 - train_loss: 0.0000  val_loss: 1.4711  cv_score: 0.8113  lr: 0.000031  time: 15s nowtime: 23,19:29.47\n",
      "Epoch 374 - train_loss: 0.0010  val_loss: 1.4749  cv_score: 0.8090  lr: 0.000031  time: 15s nowtime: 23,19:30.2\n",
      "Epoch 375 - train_loss: 0.0003  val_loss: 1.4914  cv_score: 0.8160  lr: 0.000031  time: 15s nowtime: 23,19:30.18\n",
      "Epoch 376 - train_loss: 0.0000  val_loss: 1.4938  cv_score: 0.8160  lr: 0.000028  time: 15s nowtime: 23,19:30.33\n",
      "Epoch 377 - train_loss: 0.0008  val_loss: 1.4935  cv_score: 0.8184  lr: 0.000028  time: 15s nowtime: 23,19:30.48\n",
      "Epoch 378 - train_loss: 0.0000  val_loss: 1.4787  cv_score: 0.8160  lr: 0.000028  time: 15s nowtime: 23,19:31.4\n",
      "Epoch 379 - train_loss: 0.0001  val_loss: 1.4763  cv_score: 0.8184  lr: 0.000028  time: 15s nowtime: 23,19:31.19\n",
      "Epoch 380 - train_loss: 0.0000  val_loss: 1.4742  cv_score: 0.8184  lr: 0.000028  time: 15s nowtime: 23,19:31.35\n",
      "Epoch 381 - train_loss: 0.0001  val_loss: 1.4740  cv_score: 0.8184  lr: 0.000028  time: 15s nowtime: 23,19:31.50\n",
      "Epoch 382 - train_loss: 0.0000  val_loss: 1.4726  cv_score: 0.8184  lr: 0.000028  time: 15s nowtime: 23,19:32.5\n",
      "Epoch 383 - train_loss: 0.0000  val_loss: 1.4720  cv_score: 0.8184  lr: 0.000028  time: 15s nowtime: 23,19:32.20\n",
      "Epoch 384 - train_loss: 0.0000  val_loss: 1.4715  cv_score: 0.8184  lr: 0.000028  time: 15s nowtime: 23,19:32.36\n",
      "Epoch 385 - train_loss: 0.0002  val_loss: 1.4709  cv_score: 0.8160  lr: 0.000028  time: 15s nowtime: 23,19:32.51\n",
      "Epoch 386 - train_loss: 0.0009  val_loss: 1.4723  cv_score: 0.8160  lr: 0.000028  time: 16s nowtime: 23,19:33.7\n",
      "Epoch 387 - train_loss: 0.0001  val_loss: 1.4838  cv_score: 0.8137  lr: 0.000025  time: 15s nowtime: 23,19:33.22\n",
      "Epoch 388 - train_loss: 0.0000  val_loss: 1.4848  cv_score: 0.8137  lr: 0.000025  time: 15s nowtime: 23,19:33.37\n",
      "Epoch 389 - train_loss: 0.0001  val_loss: 1.4838  cv_score: 0.8137  lr: 0.000025  time: 15s nowtime: 23,19:33.52\n",
      "Epoch 390 - train_loss: 0.0001  val_loss: 1.4835  cv_score: 0.8137  lr: 0.000025  time: 15s nowtime: 23,19:34.8\n",
      "Epoch 391 - train_loss: 0.0007  val_loss: 1.4847  cv_score: 0.8160  lr: 0.000025  time: 15s nowtime: 23,19:34.23\n",
      "Epoch 392 - train_loss: 0.0000  val_loss: 1.4846  cv_score: 0.8160  lr: 0.000025  time: 15s nowtime: 23,19:34.38\n",
      "Epoch 393 - train_loss: 0.0000  val_loss: 1.4856  cv_score: 0.8160  lr: 0.000025  time: 15s nowtime: 23,19:34.54\n",
      "Epoch 394 - train_loss: 0.0000  val_loss: 1.4848  cv_score: 0.8160  lr: 0.000025  time: 15s nowtime: 23,19:35.9\n",
      "Epoch 395 - train_loss: 0.0000  val_loss: 1.4858  cv_score: 0.8160  lr: 0.000025  time: 15s nowtime: 23,19:35.25\n",
      "Epoch 396 - train_loss: 0.0000  val_loss: 1.4837  cv_score: 0.8160  lr: 0.000025  time: 15s nowtime: 23,19:35.40\n",
      "Epoch 397 - train_loss: 0.0000  val_loss: 1.4838  cv_score: 0.8160  lr: 0.000025  time: 15s nowtime: 23,19:35.55\n",
      "Epoch 398 - train_loss: 0.0000  val_loss: 1.4839  cv_score: 0.8160  lr: 0.000023  time: 16s nowtime: 23,19:36.11\n",
      "Epoch 399 - train_loss: 0.0000  val_loss: 1.4836  cv_score: 0.8160  lr: 0.000023  time: 15s nowtime: 23,19:36.26\n",
      "Epoch 400 - train_loss: 0.0000  val_loss: 1.4846  cv_score: 0.8160  lr: 0.000023  time: 15s nowtime: 23,19:36.41\n",
      "Epoch 401 - train_loss: 0.0000  val_loss: 1.4849  cv_score: 0.8160  lr: 0.000023  time: 15s nowtime: 23,19:36.57\n",
      "Epoch 402 - train_loss: 0.0000  val_loss: 1.4848  cv_score: 0.8160  lr: 0.000023  time: 15s nowtime: 23,19:37.12\n",
      "Epoch 403 - train_loss: 0.0001  val_loss: 1.4846  cv_score: 0.8160  lr: 0.000023  time: 15s nowtime: 23,19:37.28\n",
      "Epoch 404 - train_loss: 0.0002  val_loss: 1.4852  cv_score: 0.8137  lr: 0.000023  time: 15s nowtime: 23,19:37.43\n",
      "Epoch 405 - train_loss: 0.0000  val_loss: 1.4860  cv_score: 0.8137  lr: 0.000023  time: 15s nowtime: 23,19:37.58\n",
      "Epoch 406 - train_loss: 0.0000  val_loss: 1.4859  cv_score: 0.8160  lr: 0.000023  time: 16s nowtime: 23,19:38.14\n",
      "Epoch 407 - train_loss: 0.0002  val_loss: 1.4849  cv_score: 0.8160  lr: 0.000023  time: 15s nowtime: 23,19:38.29\n",
      "Epoch 408 - train_loss: 0.0000  val_loss: 1.4847  cv_score: 0.8184  lr: 0.000023  time: 15s nowtime: 23,19:38.45\n",
      "Epoch 409 - train_loss: 0.0000  val_loss: 1.4844  cv_score: 0.8184  lr: 0.000020  time: 15s nowtime: 23,19:39.0\n",
      "Epoch 410 - train_loss: 0.0011  val_loss: 1.4834  cv_score: 0.8184  lr: 0.000020  time: 15s nowtime: 23,19:39.15\n",
      "Epoch 411 - train_loss: 0.0000  val_loss: 1.4658  cv_score: 0.8160  lr: 0.000020  time: 15s nowtime: 23,19:39.30\n",
      "Epoch 412 - train_loss: 0.0001  val_loss: 1.4618  cv_score: 0.8160  lr: 0.000020  time: 15s nowtime: 23,19:39.46\n",
      "Epoch 413 - train_loss: 0.0000  val_loss: 1.4601  cv_score: 0.8160  lr: 0.000020  time: 15s nowtime: 23,19:40.1\n",
      "Epoch 414 - train_loss: 0.0000  val_loss: 1.4587  cv_score: 0.8160  lr: 0.000020  time: 16s nowtime: 23,19:40.17\n",
      "Epoch 415 - train_loss: 0.0000  val_loss: 1.4588  cv_score: 0.8160  lr: 0.000020  time: 15s nowtime: 23,19:40.32\n",
      "Epoch 416 - train_loss: 0.0000  val_loss: 1.4591  cv_score: 0.8160  lr: 0.000020  time: 15s nowtime: 23,19:40.47\n",
      "Epoch 417 - train_loss: 0.0037  val_loss: 1.4553  cv_score: 0.8160  lr: 0.000020  time: 15s nowtime: 23,19:41.3\n",
      "Epoch 418 - train_loss: 0.0000  val_loss: 1.4274  cv_score: 0.8113  lr: 0.000020  time: 15s nowtime: 23,19:41.18\n",
      "Epoch 419 - train_loss: 0.0015  val_loss: 1.4195  cv_score: 0.8160  lr: 0.000020  time: 15s nowtime: 23,19:41.33\n",
      "Epoch 420 - train_loss: 0.0001  val_loss: 1.4178  cv_score: 0.8184  lr: 0.000018  time: 15s nowtime: 23,19:41.49\n",
      "Epoch 421 - train_loss: 0.0000  val_loss: 1.4151  cv_score: 0.8184  lr: 0.000018  time: 15s nowtime: 23,19:42.4\n",
      "Epoch 422 - train_loss: 0.0001  val_loss: 1.4149  cv_score: 0.8184  lr: 0.000018  time: 15s nowtime: 23,19:42.20\n",
      "Epoch 423 - train_loss: 0.0000  val_loss: 1.4142  cv_score: 0.8184  lr: 0.000018  time: 15s nowtime: 23,19:42.35\n",
      "Epoch 424 - train_loss: 0.0000  val_loss: 1.4134  cv_score: 0.8184  lr: 0.000018  time: 15s nowtime: 23,19:42.50\n",
      "Epoch 425 - train_loss: 0.0000  val_loss: 1.4151  cv_score: 0.8184  lr: 0.000018  time: 15s nowtime: 23,19:43.5\n",
      "Epoch 426 - train_loss: 0.0000  val_loss: 1.4129  cv_score: 0.8184  lr: 0.000018  time: 15s nowtime: 23,19:43.21\n",
      "Epoch 427 - train_loss: 0.0003  val_loss: 1.4127  cv_score: 0.8184  lr: 0.000018  time: 15s nowtime: 23,19:43.36\n",
      "Epoch 428 - train_loss: 0.0001  val_loss: 1.4149  cv_score: 0.8184  lr: 0.000018  time: 15s nowtime: 23,19:43.51\n",
      "Epoch 429 - train_loss: 0.0000  val_loss: 1.4149  cv_score: 0.8160  lr: 0.000018  time: 16s nowtime: 23,19:44.7\n",
      "Epoch 430 - train_loss: 0.0000  val_loss: 1.4146  cv_score: 0.8160  lr: 0.000018  time: 15s nowtime: 23,19:44.22\n",
      "Epoch 431 - train_loss: 0.0001  val_loss: 1.4141  cv_score: 0.8160  lr: 0.000016  time: 15s nowtime: 23,19:44.38\n",
      "Epoch 432 - train_loss: 0.0000  val_loss: 1.4149  cv_score: 0.8160  lr: 0.000016  time: 15s nowtime: 23,19:44.53\n",
      "Epoch 433 - train_loss: 0.0001  val_loss: 1.4145  cv_score: 0.8160  lr: 0.000016  time: 15s nowtime: 23,19:45.8\n",
      "Epoch 434 - train_loss: 0.0002  val_loss: 1.4145  cv_score: 0.8160  lr: 0.000016  time: 15s nowtime: 23,19:45.24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 435 - train_loss: 0.0000  val_loss: 1.4135  cv_score: 0.8160  lr: 0.000016  time: 15s nowtime: 23,19:45.39\n",
      "Epoch 436 - train_loss: 0.0001  val_loss: 1.4121  cv_score: 0.8160  lr: 0.000016  time: 15s nowtime: 23,19:45.54\n",
      "Epoch 437 - train_loss: 0.0000  val_loss: 1.4119  cv_score: 0.8160  lr: 0.000016  time: 16s nowtime: 23,19:46.10\n",
      "Epoch 438 - train_loss: 0.0002  val_loss: 1.4123  cv_score: 0.8160  lr: 0.000016  time: 15s nowtime: 23,19:46.25\n",
      "Epoch 439 - train_loss: 0.0023  val_loss: 1.4128  cv_score: 0.8137  lr: 0.000016  time: 15s nowtime: 23,19:46.41\n",
      "Epoch 440 - train_loss: 0.0001  val_loss: 1.4234  cv_score: 0.8137  lr: 0.000016  time: 15s nowtime: 23,19:46.56\n",
      "Epoch 441 - train_loss: 0.0227  val_loss: 1.4303  cv_score: 0.8184  lr: 0.000016  time: 15s nowtime: 23,19:47.11\n",
      "Epoch 442 - train_loss: 0.0000  val_loss: 1.4372  cv_score: 0.8184  lr: 0.000015  time: 15s nowtime: 23,19:47.26\n",
      "Epoch 443 - train_loss: 0.0000  val_loss: 1.4394  cv_score: 0.8208  lr: 0.000015  time: 15s nowtime: 23,19:47.42\n",
      "Epoch 444 - train_loss: 0.0000  val_loss: 1.4400  cv_score: 0.8160  lr: 0.000015  time: 15s nowtime: 23,19:47.57\n",
      "Epoch 445 - train_loss: 0.0003  val_loss: 1.4395  cv_score: 0.8160  lr: 0.000015  time: 16s nowtime: 23,19:48.13\n",
      "Epoch 446 - train_loss: 0.0000  val_loss: 1.4386  cv_score: 0.8160  lr: 0.000015  time: 16s nowtime: 23,19:48.28\n",
      "Epoch 447 - train_loss: 0.0001  val_loss: 1.4364  cv_score: 0.8184  lr: 0.000015  time: 15s nowtime: 23,19:48.43\n",
      "Epoch 448 - train_loss: 0.0004  val_loss: 1.4369  cv_score: 0.8208  lr: 0.000015  time: 15s nowtime: 23,19:48.59\n",
      "Score is higher than last model .....Saving Model.....\n",
      "Epoch 449 - train_loss: 0.0001  val_loss: 1.4284  cv_score: 0.8231  lr: 0.000015  time: 15s nowtime: 23,19:49.14\n",
      "Epoch 450 - train_loss: 0.0000  val_loss: 1.4255  cv_score: 0.8231  lr: 0.000015  time: 15s nowtime: 23,19:49.29\n",
      "Epoch 451 - train_loss: 0.0000  val_loss: 1.4246  cv_score: 0.8231  lr: 0.000015  time: 15s nowtime: 23,19:49.44\n",
      "Epoch 452 - train_loss: 0.0000  val_loss: 1.4237  cv_score: 0.8231  lr: 0.000015  time: 15s nowtime: 23,19:50.0\n",
      "Epoch 453 - train_loss: 0.0002  val_loss: 1.4269  cv_score: 0.8208  lr: 0.000013  time: 15s nowtime: 23,19:50.15\n",
      "Epoch 454 - train_loss: 0.0000  val_loss: 1.4263  cv_score: 0.8208  lr: 0.000013  time: 15s nowtime: 23,19:50.30\n",
      "Epoch 455 - train_loss: 0.0000  val_loss: 1.4265  cv_score: 0.8208  lr: 0.000013  time: 15s nowtime: 23,19:50.46\n",
      "Epoch 456 - train_loss: 0.0000  val_loss: 1.4272  cv_score: 0.8208  lr: 0.000013  time: 15s nowtime: 23,19:51.1\n",
      "Epoch 457 - train_loss: 0.0000  val_loss: 1.4269  cv_score: 0.8231  lr: 0.000013  time: 15s nowtime: 23,19:51.16\n",
      "Score is higher than last model .....Saving Model.....\n",
      "Epoch 458 - train_loss: 0.0000  val_loss: 1.4274  cv_score: 0.8255  lr: 0.000013  time: 15s nowtime: 23,19:51.32\n",
      "Epoch 459 - train_loss: 0.0001  val_loss: 1.4272  cv_score: 0.8231  lr: 0.000013  time: 15s nowtime: 23,19:51.47\n",
      "Epoch 460 - train_loss: 0.0000  val_loss: 1.4256  cv_score: 0.8231  lr: 0.000013  time: 15s nowtime: 23,19:52.2\n",
      "Epoch 461 - train_loss: 0.0001  val_loss: 1.4249  cv_score: 0.8208  lr: 0.000013  time: 15s nowtime: 23,19:52.18\n",
      "Epoch 462 - train_loss: 0.0000  val_loss: 1.4249  cv_score: 0.8208  lr: 0.000013  time: 15s nowtime: 23,19:52.33\n",
      "Epoch 463 - train_loss: 0.0000  val_loss: 1.4251  cv_score: 0.8208  lr: 0.000013  time: 15s nowtime: 23,19:52.48\n",
      "Epoch 464 - train_loss: 0.0000  val_loss: 1.4257  cv_score: 0.8208  lr: 0.000012  time: 15s nowtime: 23,19:53.4\n",
      "Epoch 465 - train_loss: 0.0000  val_loss: 1.4249  cv_score: 0.8231  lr: 0.000012  time: 15s nowtime: 23,19:53.19\n",
      "Epoch 466 - train_loss: 0.0000  val_loss: 1.4243  cv_score: 0.8231  lr: 0.000012  time: 15s nowtime: 23,19:53.34\n",
      "Epoch 467 - train_loss: 0.0001  val_loss: 1.4278  cv_score: 0.8231  lr: 0.000012  time: 15s nowtime: 23,19:53.50\n",
      "Epoch 468 - train_loss: 0.0001  val_loss: 1.4280  cv_score: 0.8231  lr: 0.000012  time: 15s nowtime: 23,19:54.5\n",
      "Epoch 469 - train_loss: 0.0000  val_loss: 1.4271  cv_score: 0.8231  lr: 0.000012  time: 15s nowtime: 23,19:54.20\n",
      "Epoch 470 - train_loss: 0.0000  val_loss: 1.4269  cv_score: 0.8231  lr: 0.000012  time: 15s nowtime: 23,19:54.36\n",
      "Epoch 471 - train_loss: 0.0000  val_loss: 1.4269  cv_score: 0.8231  lr: 0.000012  time: 15s nowtime: 23,19:54.51\n",
      "Epoch 472 - train_loss: 0.0000  val_loss: 1.4270  cv_score: 0.8231  lr: 0.000012  time: 15s nowtime: 23,19:55.6\n",
      "Epoch 473 - train_loss: 0.0001  val_loss: 1.4287  cv_score: 0.8208  lr: 0.000012  time: 16s nowtime: 23,19:55.22\n",
      "Epoch 474 - train_loss: 0.0000  val_loss: 1.4277  cv_score: 0.8184  lr: 0.000012  time: 15s nowtime: 23,19:55.37\n",
      "Epoch 475 - train_loss: 0.0000  val_loss: 1.4302  cv_score: 0.8184  lr: 0.000011  time: 15s nowtime: 23,19:55.52\n",
      "Epoch 476 - train_loss: 0.0000  val_loss: 1.4297  cv_score: 0.8208  lr: 0.000011  time: 15s nowtime: 23,19:56.8\n",
      "Epoch 477 - train_loss: 0.0000  val_loss: 1.4294  cv_score: 0.8184  lr: 0.000011  time: 16s nowtime: 23,19:56.23\n",
      "Epoch 478 - train_loss: 0.0000  val_loss: 1.4276  cv_score: 0.8184  lr: 0.000011  time: 15s nowtime: 23,19:56.39\n",
      "Epoch 479 - train_loss: 0.0001  val_loss: 1.4281  cv_score: 0.8208  lr: 0.000011  time: 15s nowtime: 23,19:56.54\n",
      "Epoch 480 - train_loss: 0.0002  val_loss: 1.4260  cv_score: 0.8184  lr: 0.000011  time: 15s nowtime: 23,19:57.10\n",
      "Epoch 481 - train_loss: 0.0001  val_loss: 1.4247  cv_score: 0.8184  lr: 0.000011  time: 15s nowtime: 23,19:57.25\n",
      "Epoch 482 - train_loss: 0.0000  val_loss: 1.4236  cv_score: 0.8208  lr: 0.000011  time: 15s nowtime: 23,19:57.40\n",
      "Epoch 483 - train_loss: 0.0000  val_loss: 1.4242  cv_score: 0.8208  lr: 0.000011  time: 15s nowtime: 23,19:57.56\n",
      "Epoch 484 - train_loss: 0.0002  val_loss: 1.4235  cv_score: 0.8184  lr: 0.000011  time: 16s nowtime: 23,19:58.11\n",
      "Epoch 485 - train_loss: 0.0000  val_loss: 1.4227  cv_score: 0.8208  lr: 0.000011  time: 16s nowtime: 23,19:58.27\n",
      "Epoch 486 - train_loss: 0.0002  val_loss: 1.4219  cv_score: 0.8184  lr: 0.000010  time: 15s nowtime: 23,19:58.42\n",
      "Epoch 487 - train_loss: 0.0000  val_loss: 1.4211  cv_score: 0.8184  lr: 0.000010  time: 15s nowtime: 23,19:58.57\n",
      "Epoch 488 - train_loss: 0.0000  val_loss: 1.4203  cv_score: 0.8184  lr: 0.000010  time: 15s nowtime: 23,19:59.13\n",
      "Epoch 489 - train_loss: 0.0000  val_loss: 1.4212  cv_score: 0.8184  lr: 0.000010  time: 15s nowtime: 23,19:59.28\n",
      "Epoch 490 - train_loss: 0.0000  val_loss: 1.4218  cv_score: 0.8208  lr: 0.000010  time: 15s nowtime: 23,19:59.43\n",
      "Epoch 491 - train_loss: 0.0000  val_loss: 1.4221  cv_score: 0.8231  lr: 0.000010  time: 15s nowtime: 23,19:59.59\n",
      "Epoch 492 - train_loss: 0.0001  val_loss: 1.4227  cv_score: 0.8184  lr: 0.000010  time: 15s nowtime: 23,20:0.14\n",
      "Epoch 493 - train_loss: 0.0006  val_loss: 1.4206  cv_score: 0.8255  lr: 0.000010  time: 15s nowtime: 23,20:0.29\n",
      "Score is higher than last model .....Saving Model.....\n",
      "Epoch 494 - train_loss: 0.0064  val_loss: 1.4199  cv_score: 0.8278  lr: 0.000010  time: 15s nowtime: 23,20:0.45\n",
      "Score is higher than last model .....Saving Model.....\n",
      "Epoch 495 - train_loss: 0.0000  val_loss: 1.4186  cv_score: 0.8302  lr: 0.000010  time: 15s nowtime: 23,20:1.0\n",
      "Epoch 496 - train_loss: 0.0000  val_loss: 1.4188  cv_score: 0.8302  lr: 0.000010  time: 15s nowtime: 23,20:1.15\n",
      "Epoch 497 - train_loss: 0.0001  val_loss: 1.4181  cv_score: 0.8302  lr: 0.000009  time: 15s nowtime: 23,20:1.31\n",
      "Epoch 498 - train_loss: 0.0000  val_loss: 1.4174  cv_score: 0.8302  lr: 0.000009  time: 15s nowtime: 23,20:1.46\n",
      "Epoch 499 - train_loss: 0.0000  val_loss: 1.4166  cv_score: 0.8278  lr: 0.000009  time: 15s nowtime: 23,20:2.1\n",
      "Epoch 500 - train_loss: 0.0000  val_loss: 1.4179  cv_score: 0.8278  lr: 0.000009  time: 15s nowtime: 23,20:2.17\n",
      "Epoch 501 - train_loss: 0.0000  val_loss: 1.4173  cv_score: 0.8278  lr: 0.000009  time: 15s nowtime: 23,20:2.32\n",
      "Epoch 502 - train_loss: 0.0000  val_loss: 1.4152  cv_score: 0.8278  lr: 0.000009  time: 15s nowtime: 23,20:2.47\n",
      "Epoch 503 - train_loss: 0.0000  val_loss: 1.4155  cv_score: 0.8278  lr: 0.000009  time: 15s nowtime: 23,20:3.2\n",
      "Epoch 504 - train_loss: 0.0000  val_loss: 1.4159  cv_score: 0.8278  lr: 0.000009  time: 15s nowtime: 23,20:3.18\n",
      "Epoch 505 - train_loss: 0.0000  val_loss: 1.4151  cv_score: 0.8278  lr: 0.000009  time: 15s nowtime: 23,20:3.33\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 506 - train_loss: 0.0000  val_loss: 1.4148  cv_score: 0.8231  lr: 0.000009  time: 15s nowtime: 23,20:3.48\n",
      "Epoch 507 - train_loss: 0.0001  val_loss: 1.4154  cv_score: 0.8231  lr: 0.000009  time: 15s nowtime: 23,20:4.4\n",
      "Epoch 508 - train_loss: 0.0002  val_loss: 1.4145  cv_score: 0.8231  lr: 0.000008  time: 15s nowtime: 23,20:4.19\n",
      "Epoch 509 - train_loss: 0.0001  val_loss: 1.4147  cv_score: 0.8184  lr: 0.000008  time: 15s nowtime: 23,20:4.34\n",
      "Epoch 510 - train_loss: 0.0000  val_loss: 1.4152  cv_score: 0.8184  lr: 0.000008  time: 15s nowtime: 23,20:4.50\n",
      "Epoch 511 - train_loss: 0.0000  val_loss: 1.4162  cv_score: 0.8184  lr: 0.000008  time: 15s nowtime: 23,20:5.5\n",
      "Epoch 512 - train_loss: 0.0000  val_loss: 1.4145  cv_score: 0.8184  lr: 0.000008  time: 15s nowtime: 23,20:5.20\n",
      "Epoch 513 - train_loss: 0.0015  val_loss: 1.4134  cv_score: 0.8184  lr: 0.000008  time: 15s nowtime: 23,20:5.36\n",
      "Epoch 514 - train_loss: 0.0003  val_loss: 1.4103  cv_score: 0.8231  lr: 0.000008  time: 15s nowtime: 23,20:5.51\n",
      "Epoch 515 - train_loss: 0.0000  val_loss: 1.4107  cv_score: 0.8231  lr: 0.000008  time: 15s nowtime: 23,20:6.7\n",
      "Epoch 516 - train_loss: 0.0002  val_loss: 1.4115  cv_score: 0.8231  lr: 0.000008  time: 16s nowtime: 23,20:6.22\n",
      "Epoch 517 - train_loss: 0.0000  val_loss: 1.4123  cv_score: 0.8208  lr: 0.000008  time: 15s nowtime: 23,20:6.37\n",
      "Epoch 518 - train_loss: 0.0000  val_loss: 1.4124  cv_score: 0.8184  lr: 0.000008  time: 15s nowtime: 23,20:6.53\n",
      "Epoch 519 - train_loss: 0.0001  val_loss: 1.4146  cv_score: 0.8208  lr: 0.000007  time: 15s nowtime: 23,20:7.8\n",
      "Epoch 520 - train_loss: 0.0000  val_loss: 1.4162  cv_score: 0.8231  lr: 0.000007  time: 15s nowtime: 23,20:7.23\n",
      "Epoch 521 - train_loss: 0.0001  val_loss: 1.4162  cv_score: 0.8231  lr: 0.000007  time: 15s nowtime: 23,20:7.39\n",
      "Epoch 522 - train_loss: 0.0000  val_loss: 1.4159  cv_score: 0.8231  lr: 0.000007  time: 15s nowtime: 23,20:7.54\n",
      "Epoch 523 - train_loss: 0.0000  val_loss: 1.4172  cv_score: 0.8231  lr: 0.000007  time: 15s nowtime: 23,20:8.10\n",
      "Epoch 524 - train_loss: 0.0005  val_loss: 1.4176  cv_score: 0.8208  lr: 0.000007  time: 15s nowtime: 23,20:8.25\n",
      "Epoch 525 - train_loss: 0.0000  val_loss: 1.4194  cv_score: 0.8184  lr: 0.000007  time: 15s nowtime: 23,20:8.40\n",
      "Epoch 526 - train_loss: 0.0000  val_loss: 1.4207  cv_score: 0.8208  lr: 0.000007  time: 15s nowtime: 23,20:8.56\n",
      "Epoch 527 - train_loss: 0.0000  val_loss: 1.4203  cv_score: 0.8208  lr: 0.000007  time: 15s nowtime: 23,20:9.11\n",
      "Epoch 528 - train_loss: 0.0000  val_loss: 1.4185  cv_score: 0.8231  lr: 0.000007  time: 15s nowtime: 23,20:9.27\n",
      "Epoch 529 - train_loss: 0.0000  val_loss: 1.4179  cv_score: 0.8208  lr: 0.000007  time: 15s nowtime: 23,20:9.42\n",
      "Epoch 530 - train_loss: 0.0000  val_loss: 1.4169  cv_score: 0.8231  lr: 0.000006  time: 15s nowtime: 23,20:9.57\n",
      "Epoch 531 - train_loss: 0.0000  val_loss: 1.4171  cv_score: 0.8208  lr: 0.000006  time: 16s nowtime: 23,20:10.13\n",
      "Epoch 532 - train_loss: 0.0000  val_loss: 1.4186  cv_score: 0.8208  lr: 0.000006  time: 15s nowtime: 23,20:10.28\n",
      "Epoch 533 - train_loss: 0.0000  val_loss: 1.4184  cv_score: 0.8184  lr: 0.000006  time: 15s nowtime: 23,20:10.44\n",
      "Epoch 534 - train_loss: 0.0001  val_loss: 1.4198  cv_score: 0.8208  lr: 0.000006  time: 15s nowtime: 23,20:10.59\n",
      "Epoch 535 - train_loss: 0.0000  val_loss: 1.4212  cv_score: 0.8231  lr: 0.000006  time: 15s nowtime: 23,20:11.14\n",
      "Epoch 536 - train_loss: 0.0000  val_loss: 1.4218  cv_score: 0.8231  lr: 0.000006  time: 15s nowtime: 23,20:11.30\n",
      "Epoch 537 - train_loss: 0.0000  val_loss: 1.4218  cv_score: 0.8231  lr: 0.000006  time: 15s nowtime: 23,20:11.45\n",
      "Epoch 538 - train_loss: 0.0001  val_loss: 1.4224  cv_score: 0.8231  lr: 0.000006  time: 15s nowtime: 23,20:12.0\n",
      "Epoch 539 - train_loss: 0.0001  val_loss: 1.4217  cv_score: 0.8231  lr: 0.000006  time: 15s nowtime: 23,20:12.16\n",
      "Epoch 540 - train_loss: 0.0003  val_loss: 1.4232  cv_score: 0.8208  lr: 0.000006  time: 15s nowtime: 23,20:12.31\n",
      "Epoch 541 - train_loss: 0.0000  val_loss: 1.4236  cv_score: 0.8208  lr: 0.000006  time: 16s nowtime: 23,20:12.47\n",
      "Epoch 542 - train_loss: 0.0002  val_loss: 1.4213  cv_score: 0.8208  lr: 0.000006  time: 15s nowtime: 23,20:13.2\n",
      "Epoch 543 - train_loss: 0.0001  val_loss: 1.4221  cv_score: 0.8208  lr: 0.000006  time: 15s nowtime: 23,20:13.18\n",
      "Epoch 544 - train_loss: 0.0001  val_loss: 1.4244  cv_score: 0.8208  lr: 0.000006  time: 16s nowtime: 23,20:13.33\n",
      "Epoch 545 - train_loss: 0.0000  val_loss: 1.4233  cv_score: 0.8184  lr: 0.000006  time: 15s nowtime: 23,20:13.49\n",
      "Epoch 546 - train_loss: 0.0000  val_loss: 1.4243  cv_score: 0.8184  lr: 0.000006  time: 15s nowtime: 23,20:14.4\n",
      "Epoch 547 - train_loss: 0.0001  val_loss: 1.4245  cv_score: 0.8184  lr: 0.000006  time: 15s nowtime: 23,20:14.19\n",
      "Epoch 548 - train_loss: 0.0001  val_loss: 1.4243  cv_score: 0.8184  lr: 0.000006  time: 15s nowtime: 23,20:14.35\n",
      "Epoch 549 - train_loss: 0.0000  val_loss: 1.4236  cv_score: 0.8184  lr: 0.000006  time: 15s nowtime: 23,20:14.50\n",
      "Epoch 550 - train_loss: 0.0000  val_loss: 1.4218  cv_score: 0.8184  lr: 0.000006  time: 15s nowtime: 23,20:15.5\n",
      "Epoch 551 - train_loss: 0.0000  val_loss: 1.4217  cv_score: 0.8184  lr: 0.000006  time: 15s nowtime: 23,20:15.20\n",
      "Epoch 552 - train_loss: 0.0006  val_loss: 1.4176  cv_score: 0.8208  lr: 0.000005  time: 15s nowtime: 23,20:15.36\n",
      "Epoch 553 - train_loss: 0.0018  val_loss: 1.4129  cv_score: 0.8208  lr: 0.000005  time: 15s nowtime: 23,20:15.51\n",
      "Epoch 554 - train_loss: 0.0000  val_loss: 1.3999  cv_score: 0.8208  lr: 0.000005  time: 15s nowtime: 23,20:16.6\n",
      "Epoch 555 - train_loss: 0.0000  val_loss: 1.3983  cv_score: 0.8208  lr: 0.000005  time: 16s nowtime: 23,20:16.22\n",
      "Epoch 556 - train_loss: 0.0001  val_loss: 1.3963  cv_score: 0.8208  lr: 0.000005  time: 15s nowtime: 23,20:16.37\n",
      "Epoch 557 - train_loss: 0.0000  val_loss: 1.3957  cv_score: 0.8208  lr: 0.000005  time: 15s nowtime: 23,20:16.53\n",
      "Epoch 558 - train_loss: 0.0000  val_loss: 1.3971  cv_score: 0.8208  lr: 0.000005  time: 15s nowtime: 23,20:17.8\n",
      "Epoch 559 - train_loss: 0.0018  val_loss: 1.3968  cv_score: 0.8208  lr: 0.000005  time: 15s nowtime: 23,20:17.23\n",
      "Epoch 560 - train_loss: 0.0000  val_loss: 1.3952  cv_score: 0.8184  lr: 0.000005  time: 15s nowtime: 23,20:17.39\n",
      "Epoch 561 - train_loss: 0.0000  val_loss: 1.3941  cv_score: 0.8208  lr: 0.000005  time: 16s nowtime: 23,20:17.54\n",
      "Epoch 562 - train_loss: 0.0000  val_loss: 1.3948  cv_score: 0.8208  lr: 0.000005  time: 15s nowtime: 23,20:18.9\n",
      "Epoch 563 - train_loss: 0.0000  val_loss: 1.3938  cv_score: 0.8208  lr: 0.000005  time: 16s nowtime: 23,20:18.25\n",
      "Epoch 564 - train_loss: 0.0000  val_loss: 1.3934  cv_score: 0.8184  lr: 0.000005  time: 15s nowtime: 23,20:18.40\n",
      "Epoch 565 - train_loss: 0.0000  val_loss: 1.3920  cv_score: 0.8184  lr: 0.000005  time: 15s nowtime: 23,20:18.56\n",
      "Epoch 566 - train_loss: 0.0000  val_loss: 1.3918  cv_score: 0.8208  lr: 0.000005  time: 15s nowtime: 23,20:19.11\n",
      "Epoch 567 - train_loss: 0.0001  val_loss: 1.3907  cv_score: 0.8208  lr: 0.000005  time: 15s nowtime: 23,20:19.26\n",
      "Epoch 568 - train_loss: 0.0000  val_loss: 1.3910  cv_score: 0.8208  lr: 0.000005  time: 15s nowtime: 23,20:19.42\n",
      "Epoch 569 - train_loss: 0.0001  val_loss: 1.3918  cv_score: 0.8208  lr: 0.000005  time: 15s nowtime: 23,20:19.57\n",
      "Epoch 570 - train_loss: 0.0000  val_loss: 1.3906  cv_score: 0.8208  lr: 0.000005  time: 16s nowtime: 23,20:20.12\n",
      "Epoch 571 - train_loss: 0.0000  val_loss: 1.3901  cv_score: 0.8184  lr: 0.000005  time: 15s nowtime: 23,20:20.28\n",
      "Epoch 572 - train_loss: 0.0042  val_loss: 1.3898  cv_score: 0.8231  lr: 0.000005  time: 15s nowtime: 23,20:20.43\n",
      "Epoch 573 - train_loss: 0.0000  val_loss: 1.3876  cv_score: 0.8208  lr: 0.000005  time: 15s nowtime: 23,20:20.58\n",
      "Epoch 574 - train_loss: 0.0000  val_loss: 1.3866  cv_score: 0.8184  lr: 0.000004  time: 15s nowtime: 23,20:21.14\n",
      "Epoch 575 - train_loss: 0.0000  val_loss: 1.3856  cv_score: 0.8184  lr: 0.000004  time: 15s nowtime: 23,20:21.29\n",
      "Epoch 576 - train_loss: 0.0000  val_loss: 1.3855  cv_score: 0.8208  lr: 0.000004  time: 15s nowtime: 23,20:21.44\n",
      "Epoch 577 - train_loss: 0.0001  val_loss: 1.3860  cv_score: 0.8208  lr: 0.000004  time: 15s nowtime: 23,20:21.59\n",
      "Epoch 578 - train_loss: 0.0000  val_loss: 1.3852  cv_score: 0.8208  lr: 0.000004  time: 15s nowtime: 23,20:22.15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 579 - train_loss: 0.0001  val_loss: 1.3854  cv_score: 0.8184  lr: 0.000004  time: 15s nowtime: 23,20:22.30\n",
      "Epoch 580 - train_loss: 0.0000  val_loss: 1.3842  cv_score: 0.8184  lr: 0.000004  time: 15s nowtime: 23,20:22.45\n",
      "Epoch 581 - train_loss: 0.0000  val_loss: 1.3864  cv_score: 0.8184  lr: 0.000004  time: 16s nowtime: 23,20:23.1\n",
      "Epoch 582 - train_loss: 0.0000  val_loss: 1.3855  cv_score: 0.8184  lr: 0.000004  time: 15s nowtime: 23,20:23.16\n",
      "Epoch 583 - train_loss: 0.0000  val_loss: 1.3859  cv_score: 0.8184  lr: 0.000004  time: 15s nowtime: 23,20:23.32\n",
      "Epoch 584 - train_loss: 0.0000  val_loss: 1.3851  cv_score: 0.8184  lr: 0.000004  time: 15s nowtime: 23,20:23.47\n",
      "Epoch 585 - train_loss: 0.0000  val_loss: 1.3853  cv_score: 0.8208  lr: 0.000004  time: 15s nowtime: 23,20:24.2\n",
      "Epoch 586 - train_loss: 0.0016  val_loss: 1.3869  cv_score: 0.8184  lr: 0.000004  time: 15s nowtime: 23,20:24.18\n",
      "Epoch 587 - train_loss: 0.0000  val_loss: 1.3819  cv_score: 0.8160  lr: 0.000004  time: 15s nowtime: 23,20:24.33\n",
      "Epoch 588 - train_loss: 0.0000  val_loss: 1.3807  cv_score: 0.8160  lr: 0.000004  time: 15s nowtime: 23,20:24.48\n",
      "Epoch 589 - train_loss: 0.0001  val_loss: 1.3803  cv_score: 0.8160  lr: 0.000004  time: 17s nowtime: 23,20:25.5\n",
      "Epoch 590 - train_loss: 0.0000  val_loss: 1.3802  cv_score: 0.8160  lr: 0.000004  time: 16s nowtime: 23,20:25.21\n",
      "Epoch 591 - train_loss: 0.0000  val_loss: 1.3793  cv_score: 0.8160  lr: 0.000004  time: 15s nowtime: 23,20:25.36\n",
      "Epoch 592 - train_loss: 0.0000  val_loss: 1.3790  cv_score: 0.8160  lr: 0.000004  time: 15s nowtime: 23,20:25.52\n",
      "Epoch 593 - train_loss: 0.0000  val_loss: 1.3783  cv_score: 0.8184  lr: 0.000004  time: 15s nowtime: 23,20:26.7\n",
      "Epoch 594 - train_loss: 0.0063  val_loss: 1.3793  cv_score: 0.8184  lr: 0.000004  time: 15s nowtime: 23,20:26.23\n",
      "Epoch 595 - train_loss: 0.0000  val_loss: 1.3768  cv_score: 0.8160  lr: 0.000004  time: 15s nowtime: 23,20:26.38\n",
      "Epoch 596 - train_loss: 0.0000  val_loss: 1.3757  cv_score: 0.8184  lr: 0.000003  time: 15s nowtime: 23,20:26.53\n",
      "Epoch 597 - train_loss: 0.0000  val_loss: 1.3753  cv_score: 0.8184  lr: 0.000003  time: 15s nowtime: 23,20:27.9\n",
      "Epoch 598 - train_loss: 0.0002  val_loss: 1.3753  cv_score: 0.8184  lr: 0.000003  time: 16s nowtime: 23,20:27.24\n",
      "Epoch 599 - train_loss: 0.0000  val_loss: 1.3753  cv_score: 0.8160  lr: 0.000003  time: 15s nowtime: 23,20:27.39\n",
      "Epoch 600 - train_loss: 0.0011  val_loss: 1.3751  cv_score: 0.8184  lr: 0.000003  time: 15s nowtime: 23,20:27.55\n",
      "Epoch 601 - train_loss: 0.0001  val_loss: 1.3758  cv_score: 0.8184  lr: 0.000003  time: 15s nowtime: 23,20:28.10\n",
      "Epoch 602 - train_loss: 0.0000  val_loss: 1.3774  cv_score: 0.8184  lr: 0.000003  time: 15s nowtime: 23,20:28.26\n",
      "Epoch 603 - train_loss: 0.0000  val_loss: 1.3783  cv_score: 0.8184  lr: 0.000003  time: 15s nowtime: 23,20:28.41\n",
      "Epoch 604 - train_loss: 0.0001  val_loss: 1.3793  cv_score: 0.8184  lr: 0.000003  time: 15s nowtime: 23,20:28.56\n",
      "Epoch 605 - train_loss: 0.0000  val_loss: 1.3783  cv_score: 0.8184  lr: 0.000003  time: 15s nowtime: 23,20:29.12\n",
      "Epoch 606 - train_loss: 0.0000  val_loss: 1.3790  cv_score: 0.8208  lr: 0.000003  time: 15s nowtime: 23,20:29.27\n",
      "Epoch 607 - train_loss: 0.0000  val_loss: 1.3778  cv_score: 0.8184  lr: 0.000003  time: 15s nowtime: 23,20:29.42\n",
      "Epoch 608 - train_loss: 0.0000  val_loss: 1.3784  cv_score: 0.8184  lr: 0.000003  time: 15s nowtime: 23,20:29.58\n",
      "Epoch 609 - train_loss: 0.0000  val_loss: 1.3786  cv_score: 0.8184  lr: 0.000003  time: 15s nowtime: 23,20:30.13\n",
      "Epoch 610 - train_loss: 0.0000  val_loss: 1.3790  cv_score: 0.8184  lr: 0.000003  time: 15s nowtime: 23,20:30.28\n",
      "Epoch 611 - train_loss: 0.0006  val_loss: 1.3786  cv_score: 0.8184  lr: 0.000003  time: 15s nowtime: 23,20:30.44\n",
      "Epoch 612 - train_loss: 0.0001  val_loss: 1.3783  cv_score: 0.8184  lr: 0.000003  time: 15s nowtime: 23,20:30.59\n",
      "Epoch 613 - train_loss: 0.0000  val_loss: 1.3780  cv_score: 0.8184  lr: 0.000003  time: 15s nowtime: 23,20:31.15\n",
      "Epoch 614 - train_loss: 0.0001  val_loss: 1.3778  cv_score: 0.8184  lr: 0.000003  time: 15s nowtime: 23,20:31.30\n",
      "Epoch 615 - train_loss: 0.0000  val_loss: 1.3780  cv_score: 0.8184  lr: 0.000003  time: 15s nowtime: 23,20:31.45\n",
      "Epoch 616 - train_loss: 0.0001  val_loss: 1.3792  cv_score: 0.8184  lr: 0.000003  time: 15s nowtime: 23,20:32.1\n",
      "Epoch 617 - train_loss: 0.0000  val_loss: 1.3785  cv_score: 0.8184  lr: 0.000003  time: 15s nowtime: 23,20:32.16\n",
      "Epoch 618 - train_loss: 0.0000  val_loss: 1.3777  cv_score: 0.8160  lr: 0.000003  time: 15s nowtime: 23,20:32.31\n",
      "Epoch 619 - train_loss: 0.0000  val_loss: 1.3787  cv_score: 0.8160  lr: 0.000003  time: 15s nowtime: 23,20:32.47\n",
      "Epoch 620 - train_loss: 0.0000  val_loss: 1.3777  cv_score: 0.8160  lr: 0.000003  time: 15s nowtime: 23,20:33.2\n",
      "Epoch 621 - train_loss: 0.0000  val_loss: 1.3788  cv_score: 0.8184  lr: 0.000003  time: 15s nowtime: 23,20:33.18\n",
      "Epoch 622 - train_loss: 0.0000  val_loss: 1.3787  cv_score: 0.8160  lr: 0.000003  time: 15s nowtime: 23,20:33.33\n",
      "Epoch 623 - train_loss: 0.0000  val_loss: 1.3797  cv_score: 0.8160  lr: 0.000003  time: 15s nowtime: 23,20:33.49\n",
      "Epoch 624 - train_loss: 0.0000  val_loss: 1.3788  cv_score: 0.8160  lr: 0.000003  time: 15s nowtime: 23,20:34.4\n",
      "Epoch 625 - train_loss: 0.0000  val_loss: 1.3780  cv_score: 0.8160  lr: 0.000003  time: 16s nowtime: 23,20:34.20\n",
      "Epoch 626 - train_loss: 0.0001  val_loss: 1.3781  cv_score: 0.8160  lr: 0.000003  time: 15s nowtime: 23,20:34.35\n",
      "Epoch 627 - train_loss: 0.0000  val_loss: 1.3785  cv_score: 0.8160  lr: 0.000003  time: 15s nowtime: 23,20:34.50\n",
      "Epoch 628 - train_loss: 0.0000  val_loss: 1.3782  cv_score: 0.8160  lr: 0.000003  time: 15s nowtime: 23,20:35.6\n",
      "Epoch 629 - train_loss: 0.0000  val_loss: 1.3782  cv_score: 0.8184  lr: 0.000002  time: 15s nowtime: 23,20:35.21\n",
      "Epoch 630 - train_loss: 0.0000  val_loss: 1.3791  cv_score: 0.8160  lr: 0.000002  time: 15s nowtime: 23,20:35.36\n",
      "Epoch 631 - train_loss: 0.0000  val_loss: 1.3783  cv_score: 0.8160  lr: 0.000002  time: 15s nowtime: 23,20:35.52\n",
      "Epoch 632 - train_loss: 0.0000  val_loss: 1.3790  cv_score: 0.8160  lr: 0.000002  time: 15s nowtime: 23,20:36.7\n",
      "Epoch 633 - train_loss: 0.0000  val_loss: 1.3795  cv_score: 0.8184  lr: 0.000002  time: 15s nowtime: 23,20:36.22\n",
      "Epoch 634 - train_loss: 0.0000  val_loss: 1.3793  cv_score: 0.8160  lr: 0.000002  time: 15s nowtime: 23,20:36.38\n",
      "Epoch 635 - train_loss: 0.0000  val_loss: 1.3802  cv_score: 0.8160  lr: 0.000002  time: 15s nowtime: 23,20:36.53\n",
      "Epoch 636 - train_loss: 0.0000  val_loss: 1.3799  cv_score: 0.8160  lr: 0.000002  time: 15s nowtime: 23,20:37.9\n",
      "Epoch 637 - train_loss: 0.0001  val_loss: 1.3786  cv_score: 0.8231  lr: 0.000002  time: 15s nowtime: 23,20:37.24\n",
      "Epoch 638 - train_loss: 0.0000  val_loss: 1.3799  cv_score: 0.8208  lr: 0.000002  time: 15s nowtime: 23,20:37.39\n",
      "Epoch 639 - train_loss: 0.0000  val_loss: 1.3793  cv_score: 0.8231  lr: 0.000002  time: 15s nowtime: 23,20:37.55\n",
      "Epoch 640 - train_loss: 0.0000  val_loss: 1.3779  cv_score: 0.8208  lr: 0.000002  time: 15s nowtime: 23,20:38.10\n",
      "Epoch 641 - train_loss: 0.0000  val_loss: 1.3777  cv_score: 0.8208  lr: 0.000002  time: 15s nowtime: 23,20:38.25\n",
      "Epoch 642 - train_loss: 0.0000  val_loss: 1.3781  cv_score: 0.8208  lr: 0.000002  time: 15s nowtime: 23,20:38.41\n",
      "Epoch 643 - train_loss: 0.0001  val_loss: 1.3781  cv_score: 0.8184  lr: 0.000002  time: 15s nowtime: 23,20:38.56\n",
      "Epoch 644 - train_loss: 0.0000  val_loss: 1.3777  cv_score: 0.8184  lr: 0.000002  time: 15s nowtime: 23,20:39.11\n",
      "Epoch 645 - train_loss: 0.0000  val_loss: 1.3783  cv_score: 0.8184  lr: 0.000002  time: 15s nowtime: 23,20:39.27\n",
      "Epoch 646 - train_loss: 0.0000  val_loss: 1.3779  cv_score: 0.8160  lr: 0.000002  time: 15s nowtime: 23,20:39.42\n",
      "Epoch 647 - train_loss: 0.0001  val_loss: 1.3782  cv_score: 0.8160  lr: 0.000002  time: 15s nowtime: 23,20:39.57\n",
      "Epoch 648 - train_loss: 0.0003  val_loss: 1.3777  cv_score: 0.8160  lr: 0.000002  time: 15s nowtime: 23,20:40.13\n",
      "Epoch 649 - train_loss: 0.0000  val_loss: 1.3779  cv_score: 0.8184  lr: 0.000002  time: 15s nowtime: 23,20:40.28\n",
      "Epoch 650 - train_loss: 0.0000  val_loss: 1.3767  cv_score: 0.8184  lr: 0.000002  time: 15s nowtime: 23,20:40.43\n",
      "Epoch 651 - train_loss: 0.0001  val_loss: 1.3779  cv_score: 0.8184  lr: 0.000002  time: 15s nowtime: 23,20:40.59\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 652 - train_loss: 0.0006  val_loss: 1.3754  cv_score: 0.8160  lr: 0.000002  time: 15s nowtime: 23,20:41.14\n",
      "Epoch 653 - train_loss: 0.0001  val_loss: 1.3743  cv_score: 0.8184  lr: 0.000002  time: 15s nowtime: 23,20:41.30\n",
      "Epoch 654 - train_loss: 0.0000  val_loss: 1.3755  cv_score: 0.8184  lr: 0.000002  time: 15s nowtime: 23,20:41.45\n",
      "Epoch 655 - train_loss: 0.0000  val_loss: 1.3766  cv_score: 0.8184  lr: 0.000002  time: 15s nowtime: 23,20:42.0\n",
      "Epoch 656 - train_loss: 0.0000  val_loss: 1.3778  cv_score: 0.8160  lr: 0.000002  time: 15s nowtime: 23,20:42.16\n",
      "Epoch 657 - train_loss: 0.0000  val_loss: 1.3771  cv_score: 0.8160  lr: 0.000002  time: 15s nowtime: 23,20:42.31\n",
      "Epoch 658 - train_loss: 0.0000  val_loss: 1.3768  cv_score: 0.8160  lr: 0.000002  time: 15s nowtime: 23,20:42.46\n",
      "Epoch 659 - train_loss: 0.0000  val_loss: 1.3778  cv_score: 0.8160  lr: 0.000002  time: 15s nowtime: 23,20:43.2\n",
      "Epoch 660 - train_loss: 0.0000  val_loss: 1.3777  cv_score: 0.8160  lr: 0.000002  time: 15s nowtime: 23,20:43.17\n",
      "Epoch 661 - train_loss: 0.0001  val_loss: 1.3804  cv_score: 0.8160  lr: 0.000002  time: 15s nowtime: 23,20:43.33\n",
      "Epoch 662 - train_loss: 0.0000  val_loss: 1.3813  cv_score: 0.8184  lr: 0.000002  time: 15s nowtime: 23,20:43.48\n",
      "Epoch 663 - train_loss: 0.0003  val_loss: 1.3800  cv_score: 0.8160  lr: 0.000002  time: 15s nowtime: 23,20:44.3\n",
      "Epoch 664 - train_loss: 0.0001  val_loss: 1.3810  cv_score: 0.8160  lr: 0.000002  time: 15s nowtime: 23,20:44.19\n",
      "Epoch 665 - train_loss: 0.0000  val_loss: 1.3795  cv_score: 0.8160  lr: 0.000002  time: 15s nowtime: 23,20:44.34\n",
      "Epoch 666 - train_loss: 0.0010  val_loss: 1.3813  cv_score: 0.8160  lr: 0.000002  time: 15s nowtime: 23,20:44.49\n",
      "Epoch 667 - train_loss: 0.0000  val_loss: 1.3801  cv_score: 0.8160  lr: 0.000002  time: 15s nowtime: 23,20:45.5\n",
      "Epoch 668 - train_loss: 0.0000  val_loss: 1.3805  cv_score: 0.8160  lr: 0.000002  time: 15s nowtime: 23,20:45.20\n",
      "Epoch 669 - train_loss: 0.0000  val_loss: 1.3797  cv_score: 0.8208  lr: 0.000002  time: 15s nowtime: 23,20:45.35\n",
      "Epoch 670 - train_loss: 0.0000  val_loss: 1.3791  cv_score: 0.8184  lr: 0.000002  time: 15s nowtime: 23,20:45.51\n",
      "Epoch 671 - train_loss: 0.0000  val_loss: 1.3787  cv_score: 0.8208  lr: 0.000002  time: 15s nowtime: 23,20:46.6\n",
      "Epoch 672 - train_loss: 0.0000  val_loss: 1.3788  cv_score: 0.8208  lr: 0.000002  time: 15s nowtime: 23,20:46.22\n",
      "Epoch 673 - train_loss: 0.0000  val_loss: 1.3797  cv_score: 0.8208  lr: 0.000002  time: 15s nowtime: 23,20:46.37\n",
      "Epoch 674 - train_loss: 0.0000  val_loss: 1.3791  cv_score: 0.8208  lr: 0.000002  time: 15s nowtime: 23,20:46.52\n",
      "Epoch 675 - train_loss: 0.0000  val_loss: 1.3792  cv_score: 0.8208  lr: 0.000002  time: 15s nowtime: 23,20:47.7\n",
      "Epoch 676 - train_loss: 0.0000  val_loss: 1.3777  cv_score: 0.8208  lr: 0.000002  time: 15s nowtime: 23,20:47.23\n",
      "Epoch 677 - train_loss: 0.0001  val_loss: 1.3778  cv_score: 0.8208  lr: 0.000002  time: 15s nowtime: 23,20:47.38\n",
      "Epoch 678 - train_loss: 0.0000  val_loss: 1.3763  cv_score: 0.8184  lr: 0.000002  time: 15s nowtime: 23,20:47.54\n",
      "Epoch 679 - train_loss: 0.0000  val_loss: 1.3761  cv_score: 0.8184  lr: 0.000002  time: 15s nowtime: 23,20:48.9\n",
      "Epoch 680 - train_loss: 0.0000  val_loss: 1.3766  cv_score: 0.8184  lr: 0.000002  time: 15s nowtime: 23,20:48.25\n",
      "Epoch 681 - train_loss: 0.0000  val_loss: 1.3766  cv_score: 0.8184  lr: 0.000002  time: 15s nowtime: 23,20:48.40\n",
      "Epoch 682 - train_loss: 0.0000  val_loss: 1.3766  cv_score: 0.8184  lr: 0.000002  time: 15s nowtime: 23,20:48.55\n",
      "Epoch 683 - train_loss: 0.0000  val_loss: 1.3765  cv_score: 0.8184  lr: 0.000002  time: 15s nowtime: 23,20:49.11\n",
      "Epoch 684 - train_loss: 0.0000  val_loss: 1.3780  cv_score: 0.8184  lr: 0.000001  time: 15s nowtime: 23,20:49.26\n",
      "Epoch 685 - train_loss: 0.0000  val_loss: 1.3773  cv_score: 0.8184  lr: 0.000001  time: 15s nowtime: 23,20:49.41\n",
      "Epoch 686 - train_loss: 0.0000  val_loss: 1.3764  cv_score: 0.8208  lr: 0.000001  time: 15s nowtime: 23,20:49.57\n",
      "Epoch 687 - train_loss: 0.0000  val_loss: 1.3769  cv_score: 0.8208  lr: 0.000001  time: 15s nowtime: 23,20:50.12\n",
      "Epoch 688 - train_loss: 0.0000  val_loss: 1.3758  cv_score: 0.8184  lr: 0.000001  time: 15s nowtime: 23,20:50.27\n",
      "Epoch 689 - train_loss: 0.0001  val_loss: 1.3763  cv_score: 0.8208  lr: 0.000001  time: 15s nowtime: 23,20:50.43\n",
      "Epoch 690 - train_loss: 0.0001  val_loss: 1.3759  cv_score: 0.8208  lr: 0.000001  time: 15s nowtime: 23,20:50.58\n",
      "Epoch 691 - train_loss: 0.0000  val_loss: 1.3752  cv_score: 0.8208  lr: 0.000001  time: 15s nowtime: 23,20:51.13\n",
      "Epoch 692 - train_loss: 0.0000  val_loss: 1.3761  cv_score: 0.8208  lr: 0.000001  time: 15s nowtime: 23,20:51.28\n",
      "Epoch 693 - train_loss: 0.0000  val_loss: 1.3770  cv_score: 0.8208  lr: 0.000001  time: 15s nowtime: 23,20:51.44\n",
      "Epoch 694 - train_loss: 0.0000  val_loss: 1.3769  cv_score: 0.8184  lr: 0.000001  time: 15s nowtime: 23,20:51.59\n",
      "Epoch 695 - train_loss: 0.0001  val_loss: 1.3775  cv_score: 0.8184  lr: 0.000001  time: 15s nowtime: 23,20:52.14\n",
      "Epoch 696 - train_loss: 0.0000  val_loss: 1.3785  cv_score: 0.8184  lr: 0.000001  time: 15s nowtime: 23,20:52.30\n",
      "Epoch 697 - train_loss: 0.0002  val_loss: 1.3783  cv_score: 0.8184  lr: 0.000001  time: 15s nowtime: 23,20:52.45\n",
      "Epoch 698 - train_loss: 0.0000  val_loss: 1.3794  cv_score: 0.8184  lr: 0.000001  time: 15s nowtime: 23,20:53.0\n",
      "Epoch 699 - train_loss: 0.0001  val_loss: 1.3806  cv_score: 0.8160  lr: 0.000001  time: 15s nowtime: 23,20:53.15\n",
      "Epoch 700 - train_loss: 0.0000  val_loss: 1.3801  cv_score: 0.8160  lr: 0.000001  time: 15s nowtime: 23,20:53.31\n",
      "Epoch 701 - train_loss: 0.0000  val_loss: 1.3793  cv_score: 0.8160  lr: 0.000001  time: 15s nowtime: 23,20:53.46\n",
      "Epoch 702 - train_loss: 0.0000  val_loss: 1.3788  cv_score: 0.8160  lr: 0.000001  time: 15s nowtime: 23,20:54.1\n",
      "Epoch 703 - train_loss: 0.0002  val_loss: 1.3783  cv_score: 0.8208  lr: 0.000001  time: 15s nowtime: 23,20:54.17\n",
      "Epoch 704 - train_loss: 0.0000  val_loss: 1.3773  cv_score: 0.8184  lr: 0.000001  time: 16s nowtime: 23,20:54.33\n"
     ]
    }
   ],
   "source": [
    "\n",
    "result_arr = []\n",
    "\n",
    "batch_size = args.batch_size\n",
    "#batch_size = 128*2\n",
    "traindataset = TrainDataset(df,root_dir = data_dir,transform = train_transform)\n",
    "train_set, val_set = torch.utils.data.random_split(traindataset, [int(len(traindataset)*0.8), len(traindataset)-int(len(traindataset)*0.8)])\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "model = EfficientNet.from_pretrained('efficientnet-b3', num_classes=5)\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(reduction='mean')\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "train_kwargs = dict(\n",
    "    train_loader=train_loader,\n",
    "    valid_loader=valid_loader,\n",
    "    model=model,\n",
    "    criterion=criterion,\n",
    ")\n",
    "\n",
    "num_epochs = args.num_epochs\n",
    "result, lrs, score = train_model(args,num_epochs=num_epochs, cv_checkpoint=True, fine_tune=False, **train_kwargs)\n",
    "result_arr.append(result)\n",
    "print(result)\n",
    "\n",
    "# learning rate plot\n",
    "plt.figure(figsize=(18,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(lrs, 'b')\n",
    "plt.xlabel('Epochs', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Learning rate', fontsize=14, fontweight='bold')\n",
    "plt.title(f' Learning rate schedule', fontsize=15, fontweight='bold')\n",
    "\n",
    "x = [x for x in range(0, num_epochs, 10)]\n",
    "y = [0.01, 0.005, 0.000001]\n",
    "ylabel = ['1e-2', '1e-4', '1e-6']\n",
    "plt.xticks(x)\n",
    "plt.yticks(y, ylabel)\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(score, 'r')\n",
    "plt.xlabel('Epochs', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Valid score', fontsize=14, fontweight='bold')\n",
    "plt.title(f'Fold  F1 Score', fontsize=15, fontweight='bold')\n",
    "\n",
    "x = [x for x in range(0, num_epochs, 10)]\n",
    "\n",
    "plt.show()\n",
    "time.sleep(5)\n",
    "plt.close()\n",
    "\n",
    "\n",
    "print(\"train finish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
